---
title: "Analyse des données des joueurs (expérimentations finales)"
output: 
  html_document:
    theme: lumen
---

```{r include = FALSE}
#setwd("C:/Users/Thomas Constant/Source/Repos/sorcerer/xp")
#install.packages("rmarkdown")
```


```{r include = FALSE}
#install.packages("data.table")
#install.packages("ggplot2")
require(data.table)
require(ggplot2)
```


```{r setup, echo=FALSE}
#----------------------------------- configuration
useMotrice = TRUE
useSensorielle = TRUE
useLogique = TRUE
drawLogit = TRUE
removeTenFirst = FALSE
removeOutliers = TRUE
plotDiffCurves = TRUE
plotDiffCurvesOutliers = TRUE
plotLinModels = FALSE
echoModels = TRUE
file = "./log_thomas_XPFINALES_WEEK2.txt"
#file = "./log_thomas_XPFINALES_WEEK1.txt"
#file = "./log_thomas_XPFINALES_WEEK1ANDWEEK2.txt"
#file = "./log_thomas_correct_motrice.txt"

#---------------------------------- fonctions

addVariables <- function(DTLoc,trace = FALSE,titre="noTitle"){
  
  #echec au lieu de succes pour diff c'est mieux
  DTLoc$perdant <- 1-DTLoc$gagnant;
  
  #normalisation de la mise
  DTLoc$miseNorm <- DTLoc$mise / 7;
  
  #difficulte évaluée par le joueur
  DTLoc$evalDiff <- 1 - DTLoc$miseNorm;
  
  #On ajoute une colonne de la difficulte estimee, a partir d'un 
  #logit de la difficulte supposée sur l'échec constaté
  mylogit <- glm(perdant ~ difficulty, data = DTLoc, family = "binomial"(link = "logit"))
  print(summary(mylogit));
  sample = data.frame(difficulty=DTLoc$difficulty);
  DTLoc$estDiff =  predict(mylogit, newdata = sample, type = "response");
  
  if(trace){
    sample = data.frame(difficulty=seq(0, 1, 0.05))
    newres = predict(mylogit, newdata = sample, type = "response")
    plot(DTLoc$difficulty, DTLoc$perdant, main=titre, xlab="Difficulté hypothétique",  ylab="Difficulté objective (estimée)",  col=rgb(0,100,0,100,maxColorValue=255))
    points(data.frame(sample,newres), type="o")
  }
  
  #erreur d'estimation de la difficulte par le joueur (exces de confiance ?)
  DTLoc$erreurdiff <- DTLoc$evalDiff - DTLoc$estDiff;
  
  #nombre de fail consecutifs
  DTNbFail <- DTLoc[1,]
  nbFailCpt = 0;#DTLoc[1,perdant]
  DTNbFail <- cbind(DTNbFail,data.table(nbFail=nbFailCpt))
  lastID <- DTLoc[1]$IDjoueur;

  for(i in 2:nrow(DTLoc)){
    if(DTLoc[i]$IDjoueur != lastID){
      nbFailCpt = 0;
    }else{
      if(DTLoc[i-1,gagnant] == 0){
        nbFailCpt = nbFailCpt+1;
      }else{
        nbFailCpt = 0;
      }
    }
    lastID = DTLoc[i]$IDjoueur;
    
    #if(nbFailCpt > 5)
    #  nbFailCpt = 5
    DTNbFail <- rbind(DTNbFail,cbind(DTLoc[i,],data.table(nbFail=nbFailCpt)))
  }
  DTLoc <- DTNbFail
  
  #nombre de wins consecutifs
  DTNbWin <- DTLoc[1,]
  nbWinCpt = 0;#DTLoc[1,gagnant]
  DTNbWin <- cbind(DTNbWin,data.table(nbWin=nbWinCpt))
  
  lastID <- DTLoc[1]$IDjoueur;
  
  for(i in 2:nrow(DTLoc)){
    if(DTLoc[i]$IDjoueur != lastID){
      nbWinCpt = 0;
    }else{
      if(DTLoc[i-1,gagnant] == 1){
        nbWinCpt = nbWinCpt+1;
      }else{
        nbWinCpt = 0;
      }
    }
      
    lastID = DTLoc[i]$IDjoueur;
    
    #if(nbWinCpt > 5)
    #  nbWinCpt = 5
    
    DTNbWin <- rbind(DTNbWin,cbind(DTLoc[i,],data.table(nbWin=nbWinCpt)))
  }
  DTLoc <- DTNbWin
  
  #On calcule une somme lissée des echecs et succes
  DTResLisse <- DTLoc[1,]
  resLisseCur <- 0
  DTResLisse <- cbind(DTResLisse,data.table(resLisse=resLisseCur))
  
  lastID <- DTLoc[1]$IDjoueur;
  alpha <- 0.6;
  
  for(i in 2:nrow(DTLoc)){
    if(DTLoc[i]$IDjoueur != lastID){
      resLisseCur = 0;
    }else{
      res <- DTLoc[i-1,gagnant]*2-1
      resLisseCur <- alpha * resLisseCur + res;
    }
    lastID = DTLoc[i]$IDjoueur;
    DTResLisse <- rbind(DTResLisse,cbind(DTLoc[i,],data.table(resLisse=resLisseCur)))
  }
  DTLoc <- DTResLisse
  
  DTLoc$resLisseBase <- DTLoc$resLisse;
  DTLoc$resLisse = exp(DTLoc$resLisseBase) / (1+exp(DTLoc$resLisseBase));

  
  return (DTLoc)
}

removeHeadTail <- function(DTLoc,nb,bHead=TRUE){
  #garder que les 20 derniers tours de chaque personne
  DTLoc <- as.data.table(DTLoc)
  setkey(DTLoc, IDjoueur, nom_du_jeu, action_de_jeu)
  if(bHead)
    DTLoc <- DTLoc[, tail(.SD, nrow(.SD)-nb), by = .(IDjoueur,nom_du_jeu)]
  else
    DTLoc <- DTLoc[, head(.SD, nrow(.SD)-nb), by = .(IDjoueur,nom_du_jeu)]
  
  
  return(DTLoc)
}

lienErreurEvalDiffResLisse <- function(DTLoc,titre="title"){
  
  plot(x=DTLoc$resLisse, y=DTLoc$erreurdiff, main=titre, xlab="Indice de confiance lissé", ylab="Erreur d'estimation de la difficulté")
    # TMP <- DTLoc[, .(meanDiffEstimated=mean(erreurdiff)),by=nbFail]
    # TMP2 <- DTLoc[, .(varUpDiffEstimated=mean(erreurdiff)+2*sd(erreurdiff)),by=nbFail]
    # TMP3 <- DTLoc[, .(varDownDiffEstimated=mean(erreurdiff)-2*sd(erreurdiff)),by=nbFail]
    # setkey(TMP,nbFail)
    # setkey(TMP2,nbFail)
    # setkey(TMP3,nbFail)
    # points(y=TMP$meanDiffEstimated, x=TMP$nbFail, col="red", type="o")
    # points(y=TMP2$varUpDiffEstimated, x=TMP2$nbFail, col="blue", type="o")
    # points(y=TMP3$varDownDiffEstimated, x=TMP3$nbFail, col="blue", type="o")
    
    print("Anova res lisse");
    fit <- aov(erreurdiff ~ resLisse, data=DTLoc);
    if(echoModels)
      print(summary(fit));
    
    print("Regression linéaire");
    fitl <- glm(DTLoc$erreurdiff ~ DTLoc$resLisse);
    abline(a =fitl$coefficients[1], b=fitl$coefficients[2], col="green")
    if(echoModels)
      print(summary(fitl));
    
    return(fit);
}

lienErreurEvalDiffFailsRepetes <- function(DTLoc,fails = TRUE,titre="title"){

  if(fails){
    
    
    
    plot(x=DTLoc$nbFail, y=DTLoc$erreurdiff, main=titre, xlab="Nombre d'échecs consécutifs (nbFail)", ylab="Erreur d'estimation de la difficulté")
    TMP <- DTLoc[, .(meanDiffEstimated=mean(erreurdiff)),by=nbFail]
    TMP2 <- DTLoc[, .(varUpDiffEstimated=mean(erreurdiff)+2*sd(erreurdiff)),by=nbFail]
    TMP3 <- DTLoc[, .(varDownDiffEstimated=mean(erreurdiff)-2*sd(erreurdiff)),by=nbFail]
    setkey(TMP,nbFail)
    setkey(TMP2,nbFail)
    setkey(TMP3,nbFail)
    points(y=TMP$meanDiffEstimated, x=TMP$nbFail, col="red", type="o")
    points(y=TMP2$varUpDiffEstimated, x=TMP2$nbFail, col="blue", type="o")
    points(y=TMP3$varDownDiffEstimated, x=TMP3$nbFail, col="blue", type="o")
    
    print("Anova")
    fit <- aov(erreurdiff ~ nbFail, data=DTLoc)
    if(echoModels)
      print(summary(fit))
    
    print("Regression linéaire")
    fitl <- glm(DTLoc$erreurdiff ~ DTLoc$nbFail)
    abline(a =fitl$coefficients[1], b=fitl$coefficients[2], col="green")
    if(echoModels)
      print(summary(fitl))
    
  }
  else{
    
    
    plot(x=DTLoc$nbWin, y=DTLoc$erreurdiff, main=titre, xlab="Nombre de succès consécutifs (nbWin)", ylab="Erreur d'estimation de la difficulté")
    TMP <- DTLoc[, .(meanDiffEstimated=mean(erreurdiff)),by=nbWin]
    TMP2 <- DTLoc[, .(varUpDiffEstimated=mean(erreurdiff)+2*sd(erreurdiff)),by=nbWin]
    TMP3 <- DTLoc[, .(varDownDiffEstimated=mean(erreurdiff)-2*sd(erreurdiff)),by=nbWin]
    setkey(TMP,nbWin)
    setkey(TMP2,nbWin)
    setkey(TMP3,nbWin)
    points(y=TMP$meanDiffEstimated, x=TMP$nbWin, col="red", type="o")
    points(y=TMP2$varUpDiffEstimated, x=TMP2$nbWin, col="blue", type="o")
    points(y=TMP3$varDownDiffEstimated, x=TMP3$nbWin, col="blue", type="o")
    #ggplot(data=DTLoc, aes(factor(DTLoc$nbWin),erreurdiff)) + geom_boxplot()
    
    print("Anova")
    fit <- aov(erreurdiff ~ nbWin, data=DTLoc)
    if(echoModels)
      print(summary(fit))
    
    fitl <- glm(DTLoc$erreurdiff ~ DTLoc$nbWin)
    abline(a =fitl$coefficients[1], b=fitl$coefficients[2], col="purple")
    print("Regression linéaire")
    if(echoModels)
      print(summary(fitl))

  }

  return(fit)
}

#plot les courbes de diff
plotCurves <- function (numStep,diffSubj,diffObj,confiance,id,nbWin,nbFail,error){
  #print(diffSubj);
  df <- data.frame(ns=numStep,do=diffObj,ds=diffSubj,c=confiance)
  pl <- ggplot(df,aes(x=ns,y=diffObj)) + ggtitle(id[1]);
  pl <- pl + geom_point(size=1);
  pl <- pl + geom_line(size=0.5,colour="#992299");
  pl <- pl + geom_line(aes(x=ns,y=diffSubj),size=0.5,colour="#992222");
  pl <- pl + geom_line(aes(x=ns,y=confiance),size=0.5,colour="#229922");
  pl <- pl + geom_line(aes(x=ns,y=error),size=0.5,colour="#555555");
  #pl <- pl + geom_line(aes(x=ns,y=nbWin),size=0.5,colour="#555555");
  #pl <- pl + geom_line(aes(x=ns,y=nbFail),size=0.5,colour="#000000");
  #pl <- pl + coord_fixed(ratio = 20);

  print(pl)  
}

description <- function(DTLoc){
  p <- ggplot(DTLoc, aes(factor(cyl), mpg))
  p + geom_boxplot()
  print(p)
}

echoPValue <- function(pv){
  
  pv = signif(pv,digits=2)
   
  if(pv<0.001) {
    return(paste(pv,"***"));
  }else if(pv<0.01){ 
    return(paste(pv,"**"));
  }else  if(pv<0.05){ 
    return(paste(pv,"*"));
  }else{
    return(paste(pv,":("));
  }
  
  return("");
}
```

```{r get_data, echo=FALSE}
#---------------------------------- traitement

#Prepa plot
#attach(mtcars)
#par(mfrow=c(5,3))

#on recup les données
csv.data <- read.csv(file,header=TRUE,sep=";")
```

# Cadre des expérimentations pilotes
<p align = "justify" >&nbsp;&nbsp; Les expérimentations pilotes ont pu être menés du 6 au 10 septembre, dans les mêmes conditions que celles prévues pour les expérimentations finales, à savoir dans les locaux du Living Lab auprès du public cible. Sur cette période, 32 personnes ont participé aux expérimentations, mais seulement 8 d'entre-elles ont pu tester la version finalisée du jeu (le prototype ayant évolué au cours de ces expérimentations). Ces huit personnes ont expérimenté les trois jeux de manière aléatoire (pour éviter tout effet d'ordre et de fatigue), réalisant 30 tours de jeu pour chaque tâche dédiée à un type de difficulté (logique, sensorielle et motrice). Au total, nous obtenons 240 observations pour un jeu, soit 720 observations recouvrant l'ensemble des trois types de difficulté.</p>

<p align = "justify" >&nbsp;&nbsp; Les données traitées et présentées ici sont tirées des 8 participants qui ont pu jouer aux versions finales des trois épreuves où la difficulté évolue suivant si le joueur est en condition d'échec ou de réussite, et non une courbe prédéfinie. Autrement dit, la difficulté augmente lorsque le joueur gagne ; puis baisse lorsque le joueur perd.</p>

&nbsp;&nbsp; Pour un joueur identifié, nous nous focalisons sur les données suivantes : 

* la **mise**, révélant leur confiance vis-à-vis de leur action de jeu ;
* le **tour de jeu**, spécifiant la position du joueur au cours de la progression (allant de 1, début du jeu, à 30, dernier tour de jeu) ;
* la **difficulté** du jeu à un tour de jeu donné (comprise entre 0 -facile- et 1 -très difficile-) ;
* l'**état de réussite** du joueur en sortie de tour, à savoir s'il est gagnant (1) ou perdant (0).

# Estimation de la difficulté objective
<p align = "justify" >&nbsp;&nbsp; Une première étape d'analyse des données récupérée consiste à vérifier si la difficulté du jeu prévue a priori par le concepteur (difficulté hypothétique) est calibrée avec celle vécue par les joueurs. Le calcul de cette difficulté "objective" est basé sur l'observation du nombre d'échec de chaque joueur pour un niveau donné de difficulté. Les trois figures suivantes permettent d'observer l'écart qui existe entre la difficulté heuristique et celle observée lors des expérimentations, et ce pour les trois jeux. Par exemple, dans le cas du jeu de déduction, pour une difficulté hypothétique a priori de 0%, la difficulté objective serait de 20%.</p>

```{r prepare_logique, echo=FALSE}
#difficulte logique
DTL <- csv.data[which(csv.data$nom_du_jeu=="Logique2"),]
DTL <- as.data.table(DTL)
DTL <- addVariables(DTL,drawLogit,titre="Jeu de déduction (difficulté logique)")
```

```{r prepare_senso, echo=FALSE}
#difficulte sensorielle
DTS <- csv.data[which(csv.data$nom_du_jeu=="Sensoriel"),]
DTS <- as.data.table(DTS)
DTS <- addVariables(DTS,drawLogit,titre="Jeu de perception visuelle (difficulté sensorielle)")
```

```{r prepare_motrice, echo=FALSE}
#difficulte motrice
DTM <- csv.data[which(csv.data$nom_du_jeu=="Motrice"),]
DTM <- as.data.table(DTM)
DTM$difficulty <-  (DTM$difficulty)/ abs(max(DTM$difficulty)) #normalisation difficulte
DTM <- addVariables(DTM,drawLogit,titre="Jeu d'adresse (difficulté motrice)")
```

# Description datas 

Au total, **`r length(unique(DTM$IDjoueur))`** joueurs dans le dataset avant suppression des outliers, donc  `r length(DTM$IDjoueur)` lignes dans la table.

##Recherche Outliers

##Ecart type de la mise

```{r echo=FALSE}
DTDesc = data.table();
DTDescM = data.table();
DTDescS = data.table();
DTDescL = data.table();
DTDescM = DTM[,.(type="Moteur",sdMise=sd(miseNorm)),by=IDjoueur]
DTDescS = DTS[,.(type="Sensorielle",sdMise=sd(miseNorm)),by=IDjoueur]
DTDescL = DTL[,.(type="Logique",sdMise=sd(miseNorm)),by=IDjoueur]
DTDesc = DTDescM;
DTDesc = rbind(DTDesc,DTDescS);
DTDesc = rbind(DTDesc,DTDescL);
p <- ggplot(DTDesc, aes(type,sdMise))
p <- p + geom_boxplot() + geom_point(shape=1) 
print(p)
outliersSdMiseM <- boxplot.stats(DTDescM$sdMise)$out
outliersSdMiseS <- boxplot.stats(DTDescS$sdMise)$out
outliersSdMiseL <- boxplot.stats(DTDescL$sdMise)$out
idOutliersM = DTDescM[sdMise %in% outliersSdMiseM]$IDjoueur
idOutliersS = DTDescS[sdMise %in% outliersSdMiseS]$IDjoueur
idOutliersL = DTDescL[sdMise %in% outliersSdMiseL]$IDjoueur
print(paste("Id out motrice sdMise:",toString(idOutliersM)))
print(paste("Id out senso sdMise:",toString(idOutliersS)))
print(paste("Id out logique sdMise:",toString(idOutliersL)))

if(plotDiffCurvesOutliers){
  if(!length(idOutliersM)==0)
    void <- DTM[IDjoueur %in% idOutliersM,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
  if(!length(idOutliersS) == 0)
    void <- DTS[IDjoueur %in% idOutliersS,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
  if(!length(idOutliersL) == 0)
    void <- DTL[IDjoueur %in% idOutliersL,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurvesOutliers == FALSE")
}

if(removeOutliers){
  DTM <- DTM[!IDjoueur %in% idOutliersM]
  DTS <- DTS[!IDjoueur %in% idOutliersS]
  DTL <- DTL[!IDjoueur %in% idOutliersL]
}else{
  print("NOT REMOVING OUTLIERS (removeOutliers == FALSE)")
}

```

## Moyenne de la mise

```{r echo=FALSE}
DTDesc = data.table();
DTDescM = data.table();
DTDescS = data.table();
DTDescL = data.table();
DTDescM = DTM[,.(type="Moteur",mMise=mean(miseNorm)),by=IDjoueur]
DTDescS = DTS[,.(type="Sensorielle",mMise=mean(miseNorm)),by=IDjoueur]
DTDescL = DTL[,.(type="Logique",mMise=mean(miseNorm)),by=IDjoueur]
DTDesc = DTDescM;
DTDesc = rbind(DTDesc,DTDescS);
DTDesc = rbind(DTDesc,DTDescL);
p <- ggplot(DTDesc, aes(type,mMise))
p <- p + geom_boxplot() + geom_point(shape=1) 
print(p)
outliersMMiseM <- boxplot.stats(DTDescM$mMise)$out
outliersMMiseS <- boxplot.stats(DTDescS$mMise)$out
outliersMMiseL <- boxplot.stats(DTDescL$mMise)$out
idOutliersM = DTDescM[mMise %in% outliersMMiseM]$IDjoueur
idOutliersS = DTDescS[mMise %in% outliersMMiseS]$IDjoueur
idOutliersL = DTDescL[mMise %in% outliersMMiseL]$IDjoueur
print(paste("Id out motrice mMise:",toString(idOutliersM)))
print(paste("Id out senso mMise:",toString(idOutliersS)))
print(paste("Id out logique mMise:",toString(idOutliersL)))

if(plotDiffCurvesOutliers){
  if(!length(idOutliersM )==0)
    void <- DTM[IDjoueur %in% idOutliersM,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
  if(!length(idOutliersS) == 0)
    void <- DTS[IDjoueur %in% idOutliersS,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
  if(!length(idOutliersL) == 0)
    void <- DTL[IDjoueur %in% idOutliersL,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurvesOutliers == FALSE")
}

if(removeOutliers){
  DTM <- DTM[!IDjoueur %in% idOutliersM]
  DTS <- DTS[!IDjoueur %in% idOutliersS]
  DTL <- DTL[!IDjoueur %in% idOutliersL]
}else{
  print("NOT REMOVING OUTLIERS (removeOutliers == FALSE)")
}
```


## Somme des mises

```{r echo=FALSE}
DTDesc = data.table();
DTDescM = data.table();
DTDescS = data.table();
DTDescL = data.table();
DTDescM = DTM[,.(type="Moteur",mMise=sum(miseNorm)),by=IDjoueur]
DTDescS = DTS[,.(type="Sensorielle",mMise=sum(miseNorm)),by=IDjoueur]
DTDescL = DTL[,.(type="Logique",mMise=sum(miseNorm)),by=IDjoueur]
DTDesc = DTDescM;
DTDesc = rbind(DTDesc,DTDescS);
DTDesc = rbind(DTDesc,DTDescL);
p <- ggplot(DTDesc, aes(type,mMise))
p <- p + geom_boxplot() + geom_point(shape=1) 
print(p)
outliersMMiseM <- boxplot.stats(DTDescM$mMise)$out
outliersMMiseS <- boxplot.stats(DTDescS$mMise)$out
outliersMMiseL <- boxplot.stats(DTDescL$mMise)$out
idOutliersM = DTDescM[mMise %in% outliersMMiseM]$IDjoueur
idOutliersS = DTDescS[mMise %in% outliersMMiseS]$IDjoueur
idOutliersL = DTDescL[mMise %in% outliersMMiseL]$IDjoueur
print(paste("Id out motrice sum Mise:",toString(idOutliersM)))
print(paste("Id out senso sum Mise:",toString(idOutliersS)))
print(paste("Id out logique sum Mise:",toString(idOutliersL)))

if(plotDiffCurvesOutliers){
  if(!length(idOutliersM )==0)
    void <- DTM[IDjoueur %in% idOutliersM,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
  if(!length(idOutliersS) == 0)
    void <- DTS[IDjoueur %in% idOutliersS,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
  if(!length(idOutliersL) == 0)
    void <- DTL[IDjoueur %in% idOutliersL,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurvesOutliers == FALSE")
}

if(removeOutliers){
  DTM <- DTM[!IDjoueur %in% idOutliersM]
  DTS <- DTS[!IDjoueur %in% idOutliersS]
  DTL <- DTL[!IDjoueur %in% idOutliersL]
}else{
  print("NOT REMOVING OUTLIERS (removeOutliers == FALSE)")
}
```

##Difficulte constatée $\sum(win)$

```{r echo=FALSE}
DTDesc = data.table();
DTDescM = data.table();
DTDescS = data.table();
DTDescL = data.table();
DTDescM = DTM[,.(type="Moteur",sWin=sum(gagnant)),by=IDjoueur]
DTDescS = DTS[,.(type="Sensorielle",sWin=sum(gagnant)),by=IDjoueur]
DTDescL = DTL[,.(type="Logique",sWin=sum(gagnant)),by=IDjoueur]
DTDesc = DTDescM;
DTDesc = rbind(DTDesc,DTDescS);
DTDesc = rbind(DTDesc,DTDescL);
p <- ggplot(DTDesc, aes(type,sWin))
p <- p + geom_boxplot() + geom_point(shape=1) 
print(p)
outliersSWinM <- boxplot.stats(DTDescM$sWin)$out
outliersSWinS <- boxplot.stats(DTDescS$sWin)$out
outliersSWinL <- boxplot.stats(DTDescL$sWin)$out
idOutliersM = DTDescM[sWin %in% outliersSWinM]$IDjoueur
idOutliersS = DTDescS[sWin %in% outliersSWinS]$IDjoueur
idOutliersL = DTDescL[sWin %in% outliersSWinL]$IDjoueur
print(paste("Id out motrice sum win:",toString(idOutliersM)))
print(paste("Id out senso sum win:",toString(idOutliersS)))
print(paste("Id out logique sum win:",toString(idOutliersL)))

if(plotDiffCurvesOutliers){
  if(!length(idOutliersM)==0)
    void <- DTM[IDjoueur %in% idOutliersM,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
  if(!length(idOutliersS) == 0)
    void <- DTS[IDjoueur %in% idOutliersS,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
  if(!length(idOutliersL) == 0)
    void <- DTL[IDjoueur %in% idOutliersL,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurvesOutliers == FALSE")
}

if(removeOutliers){
  DTM <- DTM[!IDjoueur %in% idOutliersM]
  DTS <- DTS[!IDjoueur %in% idOutliersS]
  DTL <- DTL[!IDjoueur %in% idOutliersL]
}else{
  print("NOT REMOVING OUTLIERS (removeOutliers == FALSE)")
}

```


Il reste , **`r length(unique(DTM$IDjoueur))`** joueurs en moteur, **`r length(unique(DTL$IDjoueur))`** en logique et **`r length(unique(DTL$IDjoueur))`** joueurs en senso.

# Estimation de l'excès et du manque de confiance
<p align = "justify" >&nbsp;&nbsp; Une deuxième étape consiste à vérifier si l'évolution de la difficulté du jeu a un impact sur la difficulté ressentie par les joueurs, la mise servant ici de référence. L'analyse précédente a permis de pouvoir obtenir la difficulté réelle de chaque jeu, nouvelle variable qui sert dorénavant de mesure de base pour observer les variations de la difficulté ressentie par le joueur.</p>
&nbsp;&nbsp; Deux nouvelles mesures sont ajoutées :

<p align = "justify" >* Le nombre d'échecs consécutifs du joueur (noté **nbFail**), qui permet de vérifier sa progression. Un échec faisant revenir le joueur à une tâche de difficulté moindre ; plus le joueur perd, plus la difficulté du jeu baisse.</p>

<p align = "justify" >* Le nombre de succès consécutifs du joueur (noté **nbWin**), où un succès entraîne une augmentation de la difficulté au tour suivant ; autrement dit, plus le joueur gagne, plus la difficulté augmente.</p> 

<p align = "justify" >&nbsp;&nbsp; Dans les deux cas, il n'y a modification de la progression de la difficulté que si le statut de réussite du joueur change (de gagnant à perdant, de perdant à un gagnant).</p>

<p align = "justify" >&nbsp;&nbsp; La mise, basée sur une échelle de Likert de 1 à 7 points, permet d'obtenir une appréciation pour chaque tour de jeu de la difficulté ressentie par le joueur (et non de la difficulté réelle de la tâche). La mise est donc normalisée, entre 0 et 1, à laquelle on retranche la difficulté réelle calculée en amont. Cette différence nous permet d'obtenir l'erreur d'appréciation de la difficulté du jeu, cadrée ici entre -1 et +1.</p>

<p align = "justify" >&nbsp;&nbsp; Les figures suivantes présentent ainsi, pour tous les jeux puis pour chacun d'entre-eux (et donc pour chaque type de difficulté), le nombre d'échecs consécutifs (nbFail) et de succès consécutifs (nbWin) par rapport à l'erreur d'appréciation de la difficulté par le joueur. Chaque figure est accompagnée des conclusions d'une analyse de la variance (ANOVA) et de la régression linéaire, tracée en vert. La courbe rouge correspond aux valeurs médianes, les bleues mesurent quant à elles deux fois l'écart type, signifiant le faible nombre de participants. Malgré cette limite, il est possible de commenter ces données, en attendant de les confronter à celles qui vont être récupérées sur une population plus importante lors des expérimentations finales.</p>

## Tous jeux confondus
<p align = "justify" >&nbsp;&nbsp; Pour l'ensemble des données tirées des trois jeux, on observe dans le cas d'échecs consécutifs une sur-estimation de la difficulté du jeu, laissant à penser que le joueur développe un manque de confiance quant à ses chances de réussir. A l'inverse, lorsque le joueur cumule les succès, il aurait tendance à sous-estimer la difficulté du jeu, bien que l'effet soit moins visible pour les échecs. Le manque de données pour ce cas peut en être à l'origine.</p>

```{r echo=FALSE}
#creation de la table totale
DT <- data.table()
if(useLogique) DT <- rbind(DT,DTL)
if(useMotrice) DT <- rbind(DT,DTM)
if(useSensorielle) DT <- rbind(DT,DTS)

#supprimer le debut ou la fin
if(removeTenFirst)
  DT <- removeHeadTail(DT,10);
```

### Nombre d'échecs consécutifs

```{r echo=FALSE}
#lien erreur d'eval diff (exces confiance ?) et fails ou succes répétés
fit <- lienErreurEvalDiffFailsRepetes(DT,TRUE,"Tous les jeux")
pvalDTFails = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTFails);
```

### Nombre de réussites consécutives

```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DT,FALSE,"Tous les jeux")
pvalDTWins = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTWins);
```

### Indice de confiance lissé

```{r echo=FALSE}
fit <- lienErreurEvalDiffResLisse(DT,"Tous les jeux")
pvalDTLisse = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTLisse);

```

## Difficulté logique
<p align = "justify" >&nbsp;&nbsp; Indépendamment pour le jeu de déduction, le nombre d'échecs consécutifs ne semble pas avoir un trop important impact sur l'estimation de la difficulté par le joueur, et ne conduirait pas à un manque de confiance. Une hypothèse serait que, face à ce type de difficulté, le joueur aurait plus de temps pour apprécier son aptitude à résoudre le problème donné et donc une meilleure appréciation de la difficulté. A l'inverse, il ferait preuve d'un léger excès de confiance dans le cas de succès répétés. De nouvelles données permettront de mieux cerner ces comportements.</p>

```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DTL,TRUE,"Difficulté logique")
pvalDTLFails = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTLFails);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>
```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DTL,FALSE,"Difficulté logique")
pvalDTLWins = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTLWins);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>

```{r echo=FALSE}
fit <- lienErreurEvalDiffResLisse(DTL,"Difficulté logique")
pvalDTLLisse = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTLLisse);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>

### Courbes de difficulte
```{r echo=FALSE}
if(plotDiffCurves){
  void <- DTL[,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurves == FALSE")
}
```


## Difficulté motrice
<p align = "justify" >&nbsp;&nbsp; Le jeu d'adresse ne montre qu'une légère sous-estimation de la difficulté dans le cas d'échecs consécutifs, qui tendrait à disparaître. Les résultats sont plus probants dans le cas de succès consécutifs. Là aussi, de nouvelles données permettront d'étoffer cette analyse, mais une modification de la conception du jeu pourrait permettre d'isoler les comportements. De tous, le jeu d'adresse est le plus rapide à réaliser (les tours de jeu s'enchaînant vite), ce qui peut entraîner une plus grande inattention de la part du joueur (là où la tâche de perception visuelle en requiert énormément, et celle de logique pouvant provoquer une rapide saturation cognitive).</p>

```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DTM,TRUE,"Difficulté motrice")
pvalDTMFails = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTMFails);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>
```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DTM,FALSE,"Difficulté motrice")
pvalDTMWins = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTMWins);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>
```{r echo=FALSE}
fit <- lienErreurEvalDiffResLisse(DTM,"Difficulté motrice")
pvalDTMLisse = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTMLisse);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>


### Courbes de difficulte
```{r echo=FALSE}
if(plotDiffCurves){
  void <- DTM[,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurves == FALSE")
}
```

## Difficulté sensorielle
<p align = "justify" >&nbsp;&nbsp; Reste le jeu de perception visuelle, dont les résultats semblent le mieux confirmer nos hypothèses, mettant en évidence un excès de confiance de la part du joueur lorsqu'il cumule les succès, et un manque de confiance lorsqu'il cumule les échecs.</p>

```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DTS,TRUE,"Difficulté sensorielle")
pvalDTSFails = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTSFails);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>

```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DTS,FALSE,"Difficulté sensorielle")
pvalDTSWins = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTSWins);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>
```{r echo=FALSE}
fit <- lienErreurEvalDiffResLisse(DTS,"Difficulté sensorielle")
pvalDTSLisse = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTSLisse);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>

### Courbes de difficulte
```{r echo=FALSE}
if(plotDiffCurves){
  void <- DTS[,{plotCurves(action_de_jeu,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurdiff);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurves == FALSE")
}
```

# Summary des pvalues

- All lissee `r echoPValue(pvalDTLisse);`
- Motrice lissee `r echoPValue(pvalDTMLisse)`
- Senso lissee `r echoPValue(pvalDTSLisse)`
- Logique lissee `r echoPValue(pvalDTLLisse)`

- All NBWin `r echoPValue(pvalDTWins)`
- Motrice NBWin `r echoPValue(pvalDTMWins)`
- Senso NBWin `r echoPValue(pvalDTSWins)`
- Logique NBWin `r echoPValue(pvalDTLWins)`

- All NBFails `r echoPValue(pvalDTFails)`
- Motrice NBFails `r echoPValue(pvalDTMFails)`
- Senso NBFails `r echoPValue(pvalDTSFails)`
- Logique NBFails `r echoPValue(pvalDTLFails)`

# Analyses complémentaires

<p align = "justify" >&nbsp;&nbsp; On teste ici une faiblesse éventuelle du modèle. Nous considérons qu'un joueur a une perception faussée de la difficultée si la difficulté objective globale $d_{og}$ est différente de la difficulté subjective $d_{s}$. $d_{og}$ est calculée sur l'ensemble du groupe . $d_{s}$ correspond à la mise du joueur normalisée. Nous étudions le rapport entre nombre d'échecs consécutifs $n_{fail}$ ou nombre de réussites consécutifs $n_{win}$ et l'erreur d'estimation $\epsilon = d_{s} - d_{og}$. </p>

<p align = "justify" >&nbsp;&nbsp; $d_{og}$ a une faiblesse: elle est calculée sur l'ensemble du groupe et donc ne tient pas compte du niveau spécifique de chaque joueur, elle s'éloigne donc de la difficulté réelle $d_{r}$ pour les joueurs qui sortent de la moyenne du groupe, bons ou mauvais. Donc plus un joueur s'éloigne de la moyenne des joueurs, plus l'erreur d'évaluation de la difficulté va être importante: même si $d_{s}$ est parfaite, $\mid d_{s}-d_{og} \mid$ va augmenter car $d_{og}$ devient de plus en plus fausse. Autrement dit, la correlation entre $n_{win}$ et $\epsilon$ provient elle d'une erreur sur la difficulté subjective (exces de confiance) ou sur la difficulté objective. Car justement, plus un joueur est bon (ou mauvais) plus il a de chance d'avoir des suites de succès (ou d'échecs), avant que la difficulté se soit adaptée, ce qui pourrait expliquer une corrélation entre $d_{og}$ et $n_{win}$.</p>

# Idees


