---
title: "Analyse des données des joueurs (expérimentations Toussaint)"
output: 
  html_document:
    theme: lumen
---

```{r include = FALSE}
#----------------------------------- configuration R_MD
#setwd("C:/Users/Thomas Constant/Source/Repos/sorcerer/xp")
#install.packages("rmarkdown")
```


```{r include = FALSE}
#----------------------------------- gestion des packages
#install.packages("data.table")
#install.packages("ggplot2")
#install.packages("car")
#install.packages("lmerTest")
#install.packages("data.table")
#install.packages("ggplot2")
#install.packages("xlsx")
#install.packages("plyr")
#install.packages("likert")
#install.packages("usdm")
#install.packages("MuMIn")
#install.packages("Matrix")
#install.packages("psychometric")
#install.packages("pyramid")
library("xlsx")
require(xlsx)
require(plyr)
#require(likert)
require(data.table)
require(ggplot2)
library(car)
require(lme4)
require(lmerTest)
require(Matrix)
library(usdm)
require(lattice)
require(psychometric)
require(MuMIn)
require(pyramid)
require(sjPlot)
require(arm)

```

```{r get_data, echo=FALSE}
#----------------------------------- configuration traitement des données
useMotrice = TRUE
useSensorielle = TRUE
useLogique = TRUE
removeTenFirst = FALSE

removeOutliers = TRUE

effetMixtes = TRUE

plotLogit = TRUE
plotDiffCurves = FALSE
plotDiffCurvesOutliers = TRUE
plotLinModels = TRUE
echoModels = TRUE

TEST = FALSE

#logs tirés du jeu
file = "./log_thomas_XPFINALES_WEEK2.txt"
#file = "./log_thomas_correct_motrice.txt"
#file = "./log_thomas_XPFINALES_ENCOURS.txt"

#logs tirés du questionnaire
#fileQ = "./log_questionnaire_XP_WEEK2_REWRITED.xlsx"
fileQ = "./log_questionnaire_XP_WEEK2_REWRITED.csv"

#---------------------------------- source logs jeu

#Prepa plot
#attach(mtcars)
#par(mfrow=c(5,3))

#on recup les données
dataG <- read.csv(file,header=TRUE,sep=";")
dataG <- data.table(dataG)

#effacer colonne 12 de DTGLoc (vide)
dataG <- subset(dataG, select = -12)

#---------------------------------- source logs questionnaires

#dataQ <- read.xlsx(fileQ,sheetIndex=1,header=TRUE)
dataQ <- read.csv2(fileQ,header=TRUE,sep=";")

#effacer ligne 81 (vide)
dataQ <- dataQ[-c(81), ]

#effacer colonne 37 (vide)
dataQ <- subset(dataQ, select = -37)

#---------------------------------- sexe des participants
#compter les occurences de chacun
CumulMasculin <- table(dataQ$sexe==0)
CumulFeminin <- table(dataQ$sexe==1)

#afficher les résultats (à appeller en même temps)
bpSexe <- barplot(CumulMasculin, 
              names.arg=c("Feminin", "Masculin"),
              col = c("lightblue", "lightgreen"),
              xlab="Genre",  
              ylab="Nombre de participants", 
              ylim = c(0, 60))
text(bpSexe, 0, round(CumulMasculin, 1),cex=1,pos=3) 

#---------------------------------- âge des participants
#compter les occurences de chacun
counts <- table(dataQ$age)

#afficher les résultats (à appeller en même temps)
bpAge <- barplot(counts, 
              #names.arg=c("Feminin", "Masculin"),
              col = c("lightblue", "lightgreen"),
              xlab="Âge",  
              ylab="Répartition selon les participants", 
              ylim = c(0, 15))
text(bpAge, 0, round(counts, 1),cex=1,pos=3)

#créer une pyramide des âges
#au préalable, répartir les âges suivant le sexe
# 
# library(plotrix)
#  xy.pop <- dataQ[which(dataQ$age & dataQ$sexe==0),]
# 
#  
#  xx.pop<-dataQ[which(dataQ$age & dataQ$sexe==1),]
# 
#  
#  agelabels<-c("10-14","15-19","20-24","25-29","30-34",
#   "35-39","40-44","45-49","50-54","55-59","60-64","65+")
#  
#  mcol<-color.gradient(c(0,0,0.5,1),c(0,0,0.5,1),c(1,1,0.5,1),18)
#  fcol<-color.gradient(c(1,1,0.5,1),c(0.5,0.5,0.5,1),c(0.5,0.5,0.5,1),18)
#  
#  par(mar=pyramid.plot(xy.pop,xx.pop,labels=agelabels,
#   main="Australian population pyramid 2002",lxcol=mcol,rxcol=fcol,
#   gap=0.5,show.values=TRUE))
# 
#  
#  
# agesM <- dataQ[which(dataQ$age & dataQ$sexe==0),]
# agesM <- table(agesM$age)
# 
# agesF <- dataQ[which(dataQ$age & dataQ$sexe==1),]
# agesF <- table(agesF$age)
# 
# ages <- dataQ$age
# 
# 
# 
# # agesF <- table(dataQ$age,dataQ$sexe==1)
# # 
# # ages <- table(dataQ$age)
# # 
# # ages <- as.data.frame(ages)
# # hommes <- table(dataQ$sexe==0)
# # hommes <- as.data.frame(hommes)
# # 
# # femmes <- table(dataQ$sexe==1)
# # femmes <- as.data.frame(femmes)
# # 
# # 
# # ages <- dataQ$age
# # ages <- as.data.frame(ages)
# # 
# # hommes <- dataQ$sexe==0
# # hommes <- as.data.frame(hommes)
# 
# 
# 
# dataP <- data.frame(agesM,agesF,ages)
# 
# 
# pyramid(dataP)
# pyramid(dataP, Laxis=NULL, Raxis=NULL,
#           AxisFM="g", AxisBM="", AxisBI=3, Cgap=0.3, Cstep=1, Csize=1,
#           Llab="Hommes", Rlab="Femmes", Clab="Ages", GL=TRUE, Cadj=-0.03,
#           Lcol="Cyan", Rcol="Pink", Ldens=-1, Rdens=-1, main="")


#---------------------------------- niveau d'étude des participants
#compter les occurences de chacun
counts <- table(dataQ$niveauEtude)

#afficher les résultats (à appeller en même temps)
bpEtudes <- barplot(counts, main="Niveau d'études", horiz=FALSE,
                    names.arg=c("Aucun", "BEPC", "BEP, CAP", "BAC", "BAC+2", "BAC+3", "BAC+4", "BAC+5", "BAC+8"),
                    legend.text = NULL, beside = TRUE,
                    axes = TRUE, axisnames = TRUE,
                    xlab="Diplômes",  
                    ylab="Répartition selon les participants", 
                    ylim = c(0, 35))
text(bpEtudes, 0, round(counts, 1),cex=1,pos=3) 

#---------------------------------- profil de joueur des participants
#sélectionner uniquement les données qui nous intéressent pour construire le profil

#joueurs de jeux vidéo (tous supports confondus) /!\ ne garder que le max des réponses
dataQ$maxProfilJoueurJeuVideo = pmax(dataQ$profilJoueur2,
                                     dataQ$profilJoueur3,
                                     dataQ$profilJoueur4,
                                     dataQ$profilJoueur5,
                                     dataQ$profilJoueur6)
countsJoueurJeuVideo <- table(dataQ$maxProfilJoueurJeuVideo)

#joueurs de jeux de plateau /!\ ne garder que le max des réponses
dataQ$maxProfilJoueurJeuPlateau = pmax(dataQ$profilJoueur1)
countsJoueurJeuPlateau <- table(dataQ$maxProfilJoueurJeuPlateau)

#joueurs de jeux d'argent /!\ ne garder que le max des réponses
dataQ$maxProfilJoueurJeuArgent = pmax(dataQ$profilJoueur7)
countsJoueurJeuArgent <- table(dataQ$maxProfilJoueurJeuArgent)

#afficher les résultats (à appeller en même temps) HISTO
histProfilJoueurJeuVideo <- hist(dataQ$maxProfilJoueurJeuVideo,
                    breaks=0:5,
                    main="Profil de joueur de jeux vidéo des participants",
                    xlab="Type de profil de joueur",  
                    ylab="Participants",
                    xlim = c(0, 5),
                    ylim = c(0, 55),
                    xaxt="n")
axis(side=1,at=histProfilJoueurJeuVideo$mids,labels=seq(1,5))
abline(v=mean(dataQ$maxProfilJoueurJeuVideo),col = "blue", lwd = 2)
legend("topright", legend = "1 & 2 : non joueur / 3 : joueur occasionnel / 4 : joueur régulier / 5 : pgm")

#afficher les résultats (à appeller en même temps) HISTO
histProfilJoueurJeuPlateau <- hist(dataQ$maxProfilJoueurJeuPlateau,
                    breaks=0:5,
                    main="Profil de joueur de jeux de société des participants",
                    xlab="Type de profil de joueur",  
                    ylab="Participants",
                    xlim = c(0, 5),
                    ylim = c(0, 55),
                    xaxt="n")
axis(side=1,at=histProfilJoueurJeuPlateau$mids,labels=seq(1,5))
abline(v=mean(dataQ$maxProfilJoueurJeuPlateau),col = "blue", lwd = 2)
legend("topright", legend = "1 & 2 : non joueur / 3 : joueur occasionnel / 4 : joueur régulier / 5 : pgm")

#afficher les résultats (à appeller en même temps) HISTO
histProfilJoueurJeuArgent <- hist(dataQ$maxProfilJoueurJeuArgent,
                    breaks=0:5,
                    main="Profil de joueur de jeux d'argent des participants",
                    xlab="Type de profil de joueur",  
                    ylab="Participants",
                    xlim = c(0, 5),
                    ylim = c(0, 80),
                    xaxt="n")
axis(side=1,at=histProfilJoueurJeuArgent$mids,labels=seq(1,5))
abline(v=mean(dataQ$maxProfilJoueurJeuArgent),col = "blue", lwd = 2)
legend("topright", legend = "1 & 2 : non joueur / 3 : joueur occasionnel / 4 : joueur régulier / 5 : pgm")

# #avec question sur les jeux d'argent
# #dataProfilJoueurs <- data.frame(dataQ)[,c("profilJoueur1","profilJoueur2","profilJoueur3","profilJoueur4","profilJoueur5","profilJoueur6","profilJoueur7")]
# 
# #sans question les jeux d'argent
# dataProfilJoueurs <- data.frame(dataQ)[,c("profilJoueur1","profilJoueur2","profilJoueur3","profilJoueur4","profilJoueur5","profilJoueur6")]
# 
# #somme de l'ensemble des données profilJoueur et intégration dans tableau
# dataQ$sumProfilJoueur <- rowSums(dataProfilJoueurs, na.rm=TRUE)
# # détail du résultat sumProfilJoueur (7 questions sur échelle de Likert de 1 à 5)
# # de 7 à 14 : non joueur
# # de 15 à 21 : joueur occasionnel
# # de 22 à 28 : joueur régulier
# # de 29 à 35 : pgm
# 
# #moyenne de l'ensemble des données profilJoueur et intégration dans tableau
# dataQ$meanProfilJoueur <- rowMeans(dataProfilJoueurs, na.rm=TRUE)
# 
# #afficher les résultats (à appeller en même temps) BARPLOT
# bpProfilJoueur <- barplot(dataQ$meanProfilJoueur, main="Profil de joueurs des participants", horiz=FALSE,
#                     names.arg=c("IDjoueur"),
#                     legend.text = NULL, beside = TRUE,
#                     axes = TRUE, axisnames = TRUE,
#                     xlab="Participants",  
#                     ylab="Temps de jeu (jamais = 0 / tous les jours = 5)", 
#                     ylim = c(0, 5))
# abline(h=mean(dataQ$meanProfilJoueur),col = "blue", lwd = 2)
# legend("topright", legend = "1 & 2 : non joueur / 3 : joueur occasionnel / 4 : joueur régulier / 5 : pgm")

#---------------------------------- sentiment d'auto efficacité (AE) des participants comme joueurs
#sélectionner uniquement les données qui nous intéressent pour construire le sentiment d'AE
dataProfilAE <- data.frame(dataQ)[,c("autoEffJoueur1","autoEffJoueur2","autoEffJoueur3","autoEffJoueur4","autoEffJoueur5","autoEffJoueur6","autoEffJoueur7","autoEffJoueur8","autoEffJoueur9","autoEffJoueur10")]

#somme de l'ensemble des données du sentiment d'auto efficacité et intégration dans tableau
dataQ$sumProfilAE <- rowSums(dataProfilAE, na.rm=TRUE)
# détail du résultat sumProfilAE (10 questions sur échelle de Likert de 1 à 5)
# 0 : n'a pas répondu au questionnaire, ne se considère pas comme joueur (réponse à profilJoueur8)
# de 10 à 20 : sentiment AE faible
# de 21 à 30 : sentiment AE moyen
# de 31 à 40 : sentiment AE fort
# de 41 à 50 : sentiment AE très fort (à regrouper ?)

#moyenne de l'ensemble des données du sentiment d'auto efficacité et intégration dans tableau
dataQ$meanProfilAE <- rowMeans(dataProfilAE, na.rm=TRUE)

#ne garder que les joueurs se considérant comme joueurs
meanProfilAE <- dataQ
meanProfilAE <- na.omit(meanProfilAE)
meanProfilAE <- as.data.frame(meanProfilAE)

#afficher les résultats (à appeller en même temps) BARPLOT
bpProfilAE <- barplot(meanProfilAE$meanProfilAE, main="Sentiment d'auto-efficacité des participants", horiz=FALSE,
                    names.arg=c("IDjoueur"),
                    legend.text = NULL, beside = TRUE,
                    axes = TRUE, axisnames = TRUE,
                    xlab="Participants se définissant comme joueur",  
                    ylab="Sentiment d'auto-efficacité (maximum = 5)", 
                    ylim = c(0, 5))
abline(h=mean(meanProfilAE$meanProfilAE),col = "blue", lwd = 2)

#afficher les résultats (à appeller en même temps) HISTO
histProfilAE <- hist(meanProfilAE$meanProfilAE,
                    main="Sentiment d'auto-efficacité des participants",
                    xlab="Sentiment d'auto-efficacité (maximum = 5)",  
                    ylab="Répartition selon les participants se définissant comme joueur",
                    xlim = c(1, 5),
                    ylim = c(0, 15))
abline(v=mean(meanProfilAE$meanProfilAE),col = "blue", lwd = 2)

#---------------------------------- aversion au risque (RA) des participants
#sélectionner uniquement les données qui nous intéressent pour construire le sentiment d'AE
dataProfilRA <- data.frame(dataQ)[,c("loterie1","loterie2","loterie3","loterie4","loterie5","loterie6","loterie7","loterie8","loterie9","loterie10")]

#somme de l'ensemble des données du test d'aversion au risque et intégration dans tableau
dataQ$sumProfilRA <- rowSums(dataProfilRA, na.rm=TRUE)
# nombre de choix sûrs
# 0-1 : highly risk loving
# 2 : very risk loving
# 3 : risk loving
# 4 : risk neutral
# 5 : slightly risk averse
# 6 : risk averse
# 7 : very risk averse
# 8 : highly risk avers
# 9-10 : max choix sûr

#afficher les résultats (à appeller en même temps) BARPLOT
bpProfilRisque <- barplot(dataQ$sumProfilRA, main="Aversion au risque des participants", horiz=FALSE,
                    names.arg=c("IDjoueur"),
                    legend.text = NULL, beside = TRUE,
                    axes = TRUE, axisnames = TRUE,
                    xlab="Participants",  
                    ylab="Somme des choix sûrs (maximum = 10)", 
                    ylim = c(0, 11.7))
abline(h=mean(dataQ$sumProfilRA),col = "blue", lwd = 2)
legend("top", legend = "0-1 : highly risk loving / 2 : very risk loving / 3 : risk loving / 4 : risk neutral / 5 : slightly risk averse
       6 : risk averse / 7 : very risk averse / 8 : highly risk avers / 9-10 : stay in bed")

#afficher les résultats (à appeller en même temps) HISTO
histProfilRA <- hist(dataQ$sumProfilRA,
                    breaks=2:10,
                    main="Aversion au risque des participants",
                    xlab="Somme des choix sûrs (maximum = 10)",  
                    ylab="Répartition des participants",
                    xlim = c(2, 10),
                    ylim = c(0, 25),
                    xaxt="n")
axis(side=1,at=histProfilRA$mids,labels=seq(2,9))
abline(v=mean(dataQ$sumProfilRA),col = "blue", lwd = 2)
legend("top", legend = "0-1 : highly risk loving / 2 : very risk loving / 3 : risk loving / 4 : risk neutral / 5 : slightly risk averse
       6 : risk averse / 7 : very risk averse / 8 : highly risk avers / 9-10 : stay in bed
       ")

#-------- test pour aversion au risque
wilcox.test(dataQ$sumProfilRA,mu=6, alternative = "greater");


#---------------------------------- merge des deux tables
#si nécessaire vérifier que le questionnaire est bien une table
#dataQ <- data.table(dataQ)

#placer les données dans de nouvelles tables
DTQLoc <- data.table(dataQ)
DTGLoc <- as.data.table(dataG)

#merge des deux tables en une troisième
setkey(DTGLoc,IDjoueur)
setkey(DTQLoc,IDjoueur)
DTAll <- DTGLoc[DTQLoc]

```

```{r setup, echo=FALSE}

#---------------------------------- fonctions
echoPValue <- function(pv){
  
  pv = signif(pv,digits=2)
   
  if(pv<0.001) {
    return(paste(pv,"***"));
  }else if(pv<0.01){ 
    return(paste(pv,"**"));
  }else  if(pv<0.05){ 
    return(paste(pv,"*"));
  }else if(pv<0.1){ 
    return(paste(pv,"."));
  }else{
    return(paste(pv,":("));
  }
  
  return("");
}

addVariables <- function(DTLoc,trace = FALSE,titre="noTitle"){
  
  #echec au lieu de succes pour diff c'est mieux
  DTLoc$perdant <- 1-DTLoc$gagnant;
  
  #This is FAIL: si on vire les mises, le modèle est parfait
  #DTLoc$mise = 0;
  
  #normalisation de la mise
  DTLoc$miseNorm <- DTLoc$mise / 7;
  
  #difficulte évaluée par le joueur
  DTLoc$evalDiff <- 1 - DTLoc$miseNorm;
  
  #difficulte evaluee par le joueur : logit approach
  DTLoc[,miseBin := 0][mise >= 4, miseBin := 1]
  DTLoc[,evalDiffBin := 1][mise >= 4, evalDiffBin := 0]

  # plot(x=diff,y=res,xlim=c(0,1),ylim=c(0,1))
  # abline(1,-1)
  # for(i in 1:10){
  #   lines(c(diff[i],diff[i]),c(confMin[i],confMax[i]))
  # }
  
  
  # #bidouille : On fait des groupes de joueurs mais en fait on s'en fout
  
  # diffLmer <- lmer(perdant ~ difficulty + (1 | IDjoueur), data=DTLoc);
  # #niveau du joueur = - l'effet sur la difficulté
  # niveauJoueurLmer = - ranef(diffLmer)$IDjoueur; 
  # #colnames(niveauJoueurLmer) <- c("niveau")
  # DTLevel = data.table(IDjoueur=rownames(niveauJoueurLmer),niveau=niveauJoueurLmer);
  # setnames(DTLevel,"niveau.(Intercept)","niveau")
  # setkey(DTLoc,IDjoueur)
  # setkey(DTLevel,IDjoueur)
  # DTLoc <- DTLoc[DTLevel]
  # DTLoc <- DTLoc[order(niveau)]
  # 
  # #KMEANS
  #    
  # #groups = kmeans(DTLoc$niveau, 6)$cluster
  # #   wss <- numeric(13)
  # #   for (i in 2:15) wss[i] <- sum(kmeans(DTLoc$niveau, i)$withinss)
  # #   plot(1:15, wss, type="b", xlab="Number of Clusters",  ylab="Within groups sum of squares") 
  # 
  # #hierarchical clustering
  # fit = hclust(dist(DTLoc$niveau), "ward.D2")
  # #plot(fit,hang=-1)
  # groups <- cutree(fit, k=4) 
  # DTLoc$groupLevel = groups;
  # 
  # #cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
  # ggplot(DTLoc, aes(niveau, reorder(IDjoueur, niveau),color=factor(DTLoc$groupLevel)))+ 
  #   geom_point(alpha = 0.4, size = 3.5)
  #   #scale_color_manual(values=cbbPalette) 
  #   hist(DTLoc[round(estDiff,1)==0.4]$miseNorm)
  #   hist(DTLoc[difficulty==0.4]$miseNorm)
  # 
  # ggplot(data = DTLoc, aes(x=estDiff, y=evalDiff)) + geom_boxplot(aes(group=round(estDiff,1)))
  # 
  # ggplot(data = DTLoc[groupLevel==3], aes(x=estDiff, y=evalDiff)) + geom_boxplot(aes(group=round(estDiff,1)))
  # ggplot(data = DTLoc[groupLevel==3], aes(x=difficulty, y=evalDiff)) + geom_boxplot(aes(group=difficulty))
  
 
  
  
  #Difficultée évaluée par le joueur avec un logit sur la mise mais bon 
  # mylogit <- glm(evalDiff ~ difficulty, data = DTLoc)
  # 
  # mylogit <- glm(evalDiffBin ~ difficulty, data = DTLoc, family = "binomial"(link = "logit"))
  # print(summary(mylogit));
  # sample = data.frame(difficulty=DTLoc$difficulty);
  # DTLoc$evalDiff =  predict(mylogit, newdata = sample, type = "response");
  # 
  # if(trace){
  #   sample = data.frame(difficulty=seq(0, 1, 0.05))
  #   newres = predict(mylogit, newdata = sample, type = "response")
  #   plot(DTLoc$difficulty, DTLoc$evalDiffBin, main=titre, xlab="Difficulté hypothétique",  ylab="Difficulté estimée (mise)",  col=rgb(0,100,0,100,maxColorValue=255))
  #   points(data.frame(sample,newres), type="o")
  # }
  
  #On ajoute une colonne de la difficulte estimee, a partir d'un 
  #logit de la difficulte supposée sur l'échec constaté
  mylogit <- glm(perdant ~ difficulty, data = DTLoc, family = "binomial"(link = "logit"))
  if(effetMixtes == TRUE){
     #mylogit <- lmer(perdant ~ difficulty + (1 | IDjoueur), data=DTLoc);
     mylogit <- glmer(perdant ~ difficulty + (1 | IDjoueur), data=DTLoc,family = "binomial"(link = "logit"));
     sample = data.frame(difficulty=DTLoc$difficulty, IDjoueur=DTLoc$IDjoueur);
     DTLoc$estDiff =  predict(mylogit, newdata = sample, type = "response");
  
  }else{
    sample = data.frame(difficulty=DTLoc$difficulty);
    DTLoc$estDiff =  predict(mylogit, newdata = sample, type = "response");
  }
  
  print(summary(mylogit));
  
  #sjp.glmer(mylogit, sort = "(Intercept)")
  
  niveauJoueurLmer = -ranef(mylogit)$IDjoueur; 
  DTLevel = data.table(IDjoueur=rownames(niveauJoueurLmer),niveau=niveauJoueurLmer);
  setnames(DTLevel,"niveau.(Intercept)","niveau")
  DTLevel = DTLevel[order(abs(niveau))];
  joueurMed = DTLevel[1]$IDjoueur
  DTLevel = DTLevel[order(niveau)];
  joueurMin = DTLevel[1]$IDjoueur
  joueurMax = DTLevel[nrow(DTLevel)]$IDjoueur
  
  
  for(i in 1:nrow(DTLevel)){
    sample = data.frame(difficulty=seq(0, 1, 0.05),IDjoueur=DTLevel[i]$IDjoueur)
    newres = predict(mylogit, newdata = sample, type = "response")
    DT = data.table(difficulty=seq(0, 1, 0.05),IDjoueur = DTLevel[i]$IDjoueur, estDiff = newres)
    if(i==1)
       p = ggplot(DT,aes(x=difficulty,y=estDiff)) + geom_path(alpha = 0.2) + xlim(0,1) + ylim(0,1)
    else
      p = p + geom_path(x=DT$difficulty,y=DT$estDiff, alpha = 0.2,size=1.2)
  }
  
  sample = data.frame(difficulty=seq(0, 1, 0.05),IDjoueur=joueurMed)
  newres = predict(mylogit, newdata = sample, type = "response")
  DT = data.table(difficulty=seq(0, 1, 0.05),IDjoueur = joueurMed, estDiff = newres)
  p = p + geom_path(x=DT$difficulty,y=DT$estDiff,color="blue",size=1.3)
  
  sample = data.frame(difficulty=seq(0, 1, 0.05),IDjoueur=joueurMin)
  newres = predict(mylogit, newdata = sample, type = "response")
  DT = data.table(difficulty=seq(0, 1, 0.05),IDjoueur = joueurMin, estDiff = newres)
  p = p + geom_path(x=DT$difficulty,y=DT$estDiff,color="red",size=1.3)
  
  sample = data.frame(difficulty=seq(0, 1, 0.05),IDjoueur=joueurMax)
  newres = predict(mylogit, newdata = sample, type = "response")
  DT = data.table(difficulty=seq(0, 1, 0.05),IDjoueur = joueurMax, estDiff = newres)
  p = p + geom_path(x=DT$difficulty,y=DT$estDiff,color="green",size=1.3)
  
  print(p)
      
      #GUIGUI TODO : si lmer, tracer la courbe moyenne, et +- 1  ecart type
  if(trace && effetMixtes == FALSE){
    sample = data.frame(difficulty=seq(0, 1, 0.05))
    newres = predict(mylogit, newdata = sample, type = "response")
    plot(DTLoc$difficulty, DTLoc$perdant, main=titre, xlab="Difficulté hypothétique",  ylab="Difficulté objective (estimée)",  col=rgb(0,100,0,100,maxColorValue=255))
    points(data.frame(sample,newres), type="o")
  }
  
  
  #difficulté équilibrée ? normalement oui
  p = ggplot(DTLoc,aes(x=estDiff)) + geom_histogram(col="black", fill="white")+xlim(0,1)
    
  print(p)
  # print(hist(DTLoc$estDiff,breaks=30)
  # abline(v=mean(DTLoc$estDiff),col = "blue", lwd = 2))
  # print(p + p2) 
  # 
  
  #Lien entre mise normalisée et difficultée estimée (hard / easy effect)
  res = numeric(10)
  nb = numeric(10)
  diff = numeric(10)
  test = numeric(10)
  confMin = numeric(10)
  confMax = numeric(10)
  for(i in 1:10){
    diffic = round(i/10,1)
    print(diffic)
    #res[i] = table(DTLoc[round(estDiff,1)==round(i/10,1)]$miseBin)["1"] /
    #            table(DTLoc[round(estDiff,1)==round(i/10,1)]$miseBin)["0"]
    #res[i] = mean(DTLoc[round(estDiff,1)==diffic]$miseNorm)
    data = DTLoc[round(estDiff,1)==diffic]$miseNorm;
    
    diff[i] = NA
    res[i] = NA
    if(length(data) > 1){
      result = try(wilcox.test(data,mu = 1-diffic,conf.int=T))
      if (class(result) != "try-error"){
        testWilly = wilcox.test(data,mu = 1-diffic,conf.int=T)
        test[i] = echoPValue(testWilly$p.value)
        res[i] = testWilly$estimate
        confMin[i] = testWilly$conf.int[1]
        confMax[i] = testWilly$conf.int[2]
        nb[i] = length(data)
        diff[i] = diffic
      }
    }
  }
  #plot(diff,res,log="y")
  print(data.table(estDiff=diff,pval=test))
  
  DT = data.table(difficulty=diff,miseNorm=res)
  p = ggplot(DT, aes(difficulty,miseNorm)) + 
    geom_point(alpha = 0.4, size = 3.5) + 
    xlim(0,1)+
    ylim(0,1)+
  geom_errorbar(aes(ymin=confMin, ymax=confMax), width=.01,color="red")  + 
    geom_abline(intercept = 1, slope = -1, color="blue")
  print(p)
  
  
  
  #erreur d'estimation de la difficulte par le joueur (exces de confiance ?)
  DTLoc$erreurDiffConfiance <- DTLoc$estDiff - DTLoc$evalDiff;
  
  #nombre de fails
  temps <- proc.time()[1];
  gagnant = DTLoc$gagnant; #sous table, pour gagner du temps au lookup
  id = DTLoc$IDjoueur; #sous table, pour gagner du temps au lookup
  
  nbFailCpt = 0;
  lastID <- id[1];
  res <- numeric(nrow(DTLoc))
  res[1] = 0;
  resLastFail <- numeric(nrow(DTLoc))
  resLastFail[1] = 0;
  
  for(i in 2:nrow(DTLoc)){
    if(id[i] != lastID){
      nbFailCpt = 0;
      resLastFail[i] = 0;
    }else{
      if(gagnant[i-1] == 0){
        nbFailCpt = nbFailCpt+1;
        resLastFail[i] = 1;
      }else{
        nbFailCpt = 0;
        resLastFail[i] = 0;
      }
    }
    
    lastID = id[i-1];

    #if(nbFailCpt > 5)
      #nbFailCpt = 5

    res[i] <- nbFailCpt;
  }
  
  DTLoc$nbFail = res;
  DTLoc$lastFail = res;

  print(paste("Fails:",toString(proc.time()[1]-temps)))
  temps <- proc.time()[1];
  
  nbWinCpt = 0;
  lastWin = 0;
  lastID <- id[1];
  res <- numeric(nrow(DTLoc))
  res[1] = 0;
  resLastWin <- numeric(nrow(DTLoc))
  resLastWin[1] = 0;
  
  
  for(i in 2:nrow(DTLoc)){
    
    if(id[i] != lastID){
      nbWinCpt = 0;
      resLastWin[i] = 0;
    }else{
      if(gagnant[i-1] == 1){
        nbWinCpt = nbWinCpt+1;
        resLastWin[i] = 1;
      }else{
        nbWinCpt = 0;
        resLastWin[i] = 0;
      }
    }
    lastID = id[i];
    
    #if(nbWinCpt > 5)
     # nbWinCpt = 5

    res[i] <- nbWinCpt;
  }
  
  DTLoc$nbWin = res;
  DTLoc$lastWin = resLastWin;

  print(paste("Wins:",toString(proc.time()[1]-temps)))
  temps <- proc.time()[1];
  
  
  #On calcule une somme lissée des echecs et succes
  resLisseCur = 0;
  lastID <- id[1];
  res <- numeric(nrow(DTLoc))
  res[1] = 0;
  
  diffObj = DTLoc$estDiff;
  
  alpha <- 0.9;
  
  for(i in 2:nrow(DTLoc)){
    if(id[i] != lastID){
      resLisseCur = 0;
    }else{
      #confiance <- gagnant[i-1]*2-1
      if(gagnant[i-1]){
        confiance = diffObj[i-1];
      }else{
        confiance = -(1 - diffObj[i-1]);
      }
      resLisseCur <- alpha * resLisseCur + confiance;
    }
    lastID = id[i];
    res[i] = resLisseCur;
  }
  
  DTLoc$resLisseBase = res;
  DTLoc$resLisse = exp(DTLoc$resLisseBase) / (1+exp(DTLoc$resLisseBase));
  
  print(paste("Lissee:",toString(proc.time()[1]-temps)))
  temps <- proc.time()[1];
  
  #delta de mise cumulé pour trouvé les mecs qui font du 1/7/1/7/1/7
  cumulDeltaMise = 0;
  mise = DTLoc$mise;
  lastID <- id[1];
  res <- numeric(nrow(DTLoc))
  res[1] = 0;
  
  for(i in 2:nrow(DTLoc)){
    
    if(id[i] != lastID){
      cumulDeltaMise = 0;
    }else{
      cumulDeltaMise = cumulDeltaMise + abs(mise[i] - mise[i-1]);
    }
    lastID = id[i];
    res[i] = cumulDeltaMise;
  }
  
  DTLoc$cumulDeltaMise = res;

  
  return (DTLoc)
}

removeHeadTail <- function(DTLoc,nb,bHead=TRUE){
  #garder que les 20 derniers tours de chaque personne
  DTLoc <- as.data.table(DTLoc)
  setkey(DTLoc, IDjoueur, nom_du_jeu, action_de_jeu)
  if(bHead)
    DTLoc <- DTLoc[, tail(.SD, nrow(.SD)-nb), by = .(IDjoueur,nom_du_jeu)]
  else
    DTLoc <- DTLoc[, head(.SD, nrow(.SD)-nb), by = .(IDjoueur,nom_du_jeu)]
  
  
  return(DTLoc)
}

lienErreurEvalDiffResLisse <- function(DTLoc,titre="title"){
  
  plot(x=DTLoc$resLisse, y=DTLoc$erreurDiffConfiance, main=titre, xlab="Indice de confiance lissé", ylab="Erreur d'estimation de la difficulté")
    # TMP <- DTLoc[, .(meanDiffEstimated=mean(erreurDiffConfiance)),by=nbFail]
    # TMP2 <- DTLoc[, .(varUpDiffEstimated=mean(erreurDiffConfiance)+2*sd(erreurDiffConfiance)),by=nbFail]
    # TMP3 <- DTLoc[, .(varDownDiffEstimated=mean(erreurDiffConfiance)-2*sd(erreurDiffConfiance)),by=nbFail]
    # setkey(TMP,nbFail)
    # setkey(TMP2,nbFail)
    # setkey(TMP3,nbFail)
    # points(y=TMP$meanDiffEstimated, x=TMP$nbFail, col="red", type="o")
    # points(y=TMP2$varUpDiffEstimated, x=TMP2$nbFail, col="blue", type="o")
    # points(y=TMP3$varDownDiffEstimated, x=TMP3$nbFail, col="blue", type="o")
    
    print("Anova res lisse");
    fit <- aov(erreurDiffConfiance ~ resLisse, data=DTLoc);
    if(echoModels)
      print(summary(fit));
    
    print("Regression linéaire");
    fitl <- glm(DTLoc$erreurDiffConfiance ~ DTLoc$resLisse);
    abline(a =fitl$coefficients[1], b=fitl$coefficients[2], col="green")
    if(echoModels)
      print(summary(fitl));
    
    return(fit);
}

lienErreurEvalDiffFailsRepetes <- function(DTLoc,fails = TRUE,titre="title"){

  if(fails){
    
    
    
    plot(x=DTLoc$nbFail, y=DTLoc$erreurDiffConfiance, main=titre, xlab="Nombre d'échecs consécutifs (nbFail)", ylab="Erreur d'estimation de la difficulté")
    TMP <- DTLoc[, .(meanDiffEstimated=mean(erreurDiffConfiance)),by=nbFail]
    TMP2 <- DTLoc[, .(varUpDiffEstimated=mean(erreurDiffConfiance)+2*sd(erreurDiffConfiance)),by=nbFail]
    TMP3 <- DTLoc[, .(varDownDiffEstimated=mean(erreurDiffConfiance)-2*sd(erreurDiffConfiance)),by=nbFail]
    setkey(TMP,nbFail)
    setkey(TMP2,nbFail)
    setkey(TMP3,nbFail)
    points(y=TMP$meanDiffEstimated, x=TMP$nbFail, col="red", type="o")
    points(y=TMP2$varUpDiffEstimated, x=TMP2$nbFail, col="blue", type="o")
    points(y=TMP3$varDownDiffEstimated, x=TMP3$nbFail, col="blue", type="o")
    
    print("Anova")
    fit <- aov(erreurDiffConfiance ~ nbFail, data=DTLoc)
    if(echoModels)
      print(summary(fit))
    
    print("Regression linéaire")
    fitl <- glm(DTLoc$erreurDiffConfiance ~ DTLoc$nbFail)
    abline(a =fitl$coefficients[1], b=fitl$coefficients[2], col="green")
    if(echoModels)
      print(summary(fitl))
    
  }
  else{
    
    
    plot(x=DTLoc$nbWin, y=DTLoc$erreurDiffConfiance, main=titre, xlab="Nombre de succès consécutifs (nbWin)", ylab="Erreur d'estimation de la difficulté")
    TMP <- DTLoc[, .(meanDiffEstimated=mean(erreurDiffConfiance)),by=nbWin]
    TMP2 <- DTLoc[, .(varUpDiffEstimated=mean(erreurDiffConfiance)+2*sd(erreurDiffConfiance)),by=nbWin]
    TMP3 <- DTLoc[, .(varDownDiffEstimated=mean(erreurDiffConfiance)-2*sd(erreurDiffConfiance)),by=nbWin]
    setkey(TMP,nbWin)
    setkey(TMP2,nbWin)
    setkey(TMP3,nbWin)
    points(y=TMP$meanDiffEstimated, x=TMP$nbWin, col="red", type="o")
    points(y=TMP2$varUpDiffEstimated, x=TMP2$nbWin, col="blue", type="o")
    points(y=TMP3$varDownDiffEstimated, x=TMP3$nbWin, col="blue", type="o")
    #ggplot(data=DTLoc, aes(factor(DTLoc$nbWin),erreurDiffConfiance)) + geom_boxplot()
    
    print("Anova")
    fit <- aov(erreurDiffConfiance ~ nbWin, data=DTLoc)
    if(echoModels)
      print(summary(fit))
    
    fitl <- glm(DTLoc$erreurDiffConfiance ~ DTLoc$nbWin)
    abline(a =fitl$coefficients[1], b=fitl$coefficients[2], col="purple")
    print("Regression linéaire")
    if(echoModels)
      print(summary(fitl))

  }

  return(fit)
}

#plot les courbes de diff
plotCurves <- function (numStep,difficulty,diffSubj,diffObj,confiance,id,nbWin,nbFail,error,mise,title){
  df <- data.frame(ns=numStep,do=diffObj,ds=diffSubj,c=confiance)
  pl <- ggplot(df,aes(x=ns)) # + ggtitle(id[1]);
  pl <- pl + geom_point(aes(y=difficulty,colour="Difficulté du jeu"),size=1);
  pl <- pl + geom_line(aes(y=difficulty,colour="Difficulté du jeu"));
  pl <- pl + geom_line(aes(y=diffObj,colour="Difficulté Objective"));
  pl <- pl + geom_line(aes(y=diffSubj,colour="Difficulté Subjective"));
  pl <- pl + geom_line(aes(y=confiance,colour="Confiance"));
  pl <- pl + geom_line(aes(y=mise,colour="Mise"));
  pl <- pl + ylim(0, 1)
  pl <- pl + scale_colour_manual(
    values = c("Difficulté du jeu" = "red","Difficulté Objective" = "pink","Difficulté Subjective" = "blue","Confiance" = "green", "Mise" = "black"))
  
  #pl <- pl + geom_line(aes(x=ns,y=nbWin),size=0.5,colour="#555555");
  #pl <- pl + geom_line(aes(x=ns,y=nbFail),size=0.5,colour="#000000");
  #pl <- pl + coord_fixed(ratio = 20);
  pl <- pl  +  ggtitle(title);

  print(pl)  
}

description <- function(DTLoc){
  p <- ggplot(DTLoc, aes(factor(cyl), mpg))
  p + geom_boxplot()
  print(p)
}


```

# Cadre des expérimentations pilotes
<p align = "justify" >&nbsp;&nbsp; Les expérimentations pilotes ont pu être menés du 6 au 10 septembre, dans les mêmes conditions que celles prévues pour les expérimentations finales, à savoir dans les locaux du Living Lab auprès du public cible. Sur cette période, 32 personnes ont participé aux expérimentations, mais seulement 8 d'entre-elles ont pu tester la version finalisée du jeu (le prototype ayant évolué au cours de ces expérimentations). Ces huit personnes ont expérimenté les trois jeux de manière aléatoire (pour éviter tout effet d'ordre et de fatigue), réalisant 30 tours de jeu pour chaque tâche dédiée à un type de difficulté (logique, sensorielle et motrice). Au total, nous obtenons 240 observations pour un jeu, soit 720 observations recouvrant l'ensemble des trois types de difficulté.</p>

<p align = "justify" >&nbsp;&nbsp; Les données traitées et présentées ici sont tirées des 8 participants qui ont pu jouer aux versions finales des trois épreuves où la difficulté évolue suivant si le joueur est en condition d'échec ou de réussite, et non une courbe prédéfinie. Autrement dit, la difficulté augmente lorsque le joueur gagne ; puis baisse lorsque le joueur perd.</p>

&nbsp;&nbsp; Pour un joueur identifié, nous nous focalisons sur les données suivantes : 

* la **mise**, révélant leur confiance vis-à-vis de leur action de jeu ;
* le **tour de jeu**, spécifiant la position du joueur au cours de la progression (allant de 1, début du jeu, à 30, dernier tour de jeu) ;
* la **difficulté** du jeu à un tour de jeu donné (comprise entre 0 -facile- et 1 -très difficile-) ;
* l'**état de réussite** du joueur en sortie de tour, à savoir s'il est gagnant (1) ou perdant (0).

# Estimation de la difficulté objective
<p align = "justify" >&nbsp;&nbsp; Une première étape d'analyse des données récupérée consiste à vérifier si la difficulté du jeu prévue a priori par le concepteur (difficulté hypothétique) est calibrée avec celle vécue par les joueurs. Le calcul de cette difficulté "objective" est basé sur l'observation du nombre d'échec de chaque joueur pour un niveau donné de difficulté. Les trois figures suivantes permettent d'observer l'écart qui existe entre la difficulté heuristique et celle observée lors des expérimentations, et ce pour les trois jeux. Par exemple, dans le cas du jeu de déduction, pour une difficulté hypothétique a priori de 0%, la difficulté objective serait de 20%.</p>

```{r prepare_logique, echo=FALSE}
#difficulte logique
DTL <- dataG[which(dataG$nom_du_jeu=="Logique2"),]
DTL <- as.data.table(DTL)
DTL <- addVariables(DTL,plotLogit,titre="Jeu de déduction (difficulté logique)")
```

```{r prepare_senso, echo=FALSE}
#difficulte sensorielle
DTS <- dataG[which(dataG$nom_du_jeu=="Sensoriel"),]
DTS <- as.data.table(DTS)
DTS <- addVariables(DTS,plotLogit,titre="Jeu de perception visuelle (difficulté sensorielle)")
```

```{r prepare_motrice, echo=FALSE}
#difficulte motrice
DTM <- dataG[which(dataG$nom_du_jeu=="Motrice"),]
DTM <- as.data.table(DTM)
DTM$difficulty <-  (DTM$difficulty)/ abs(max(DTM$difficulty)) #normalisation difficulte
DTM <- addVariables(DTM,plotLogit,titre="Jeu d'adresse (difficulté motrice)")
```

# Description datas 

Au total, **`r length(unique(DTM$IDjoueur))`** joueurs dans le dataset avant suppression des outliers, donc  `r length(DTM$IDjoueur)` lignes dans la table.

##Recherche Outliers

##Ecart type de la mise

```{r echo=FALSE}
DTDesc = data.table();
DTDescM = data.table();
DTDescS = data.table();
DTDescL = data.table();
DTDescM = DTM[,.(type="Moteur",sdMise=sd(miseNorm)),by=IDjoueur]
DTDescS = DTS[,.(type="Sensorielle",sdMise=sd(miseNorm)),by=IDjoueur]
DTDescL = DTL[,.(type="Logique",sdMise=sd(miseNorm)),by=IDjoueur]
DTDesc = DTDescM;
DTDesc = rbind(DTDesc,DTDescS);
DTDesc = rbind(DTDesc,DTDescL);
p <- ggplot(DTDesc, aes(type,sdMise)) + 
              xlab("Types de difficulté") + 
              ylab("Ecart type de la mise") +
              ggtitle("Isoler les stratégies critiques")
p <- p + geom_boxplot() + geom_point(shape=1) 
print(p)
outliersSdMiseM <- boxplot.stats(DTDescM$sdMise)$out
outliersSdMiseS <- boxplot.stats(DTDescS$sdMise)$out
outliersSdMiseL <- boxplot.stats(DTDescL$sdMise)$out
idOutliersM = DTDescM[sdMise %in% outliersSdMiseM]$IDjoueur
idOutliersS = DTDescS[sdMise %in% outliersSdMiseS]$IDjoueur
idOutliersL = DTDescL[sdMise %in% outliersSdMiseL]$IDjoueur
print(paste("Id out motrice sdMise:",toString(idOutliersM)))
print(paste("Id out senso sdMise:",toString(idOutliersS)))
print(paste("Id out logique sdMise:",toString(idOutliersL)))

if(plotDiffCurvesOutliers){
  if(!length(idOutliersM)==0)
    void <- DTM[IDjoueur %in% idOutliersM,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersS) == 0)
    void <- DTS[IDjoueur %in% idOutliersS,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersL) == 0)
    void <- DTL[IDjoueur %in% idOutliersL,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurvesOutliers == FALSE")
}

if(removeOutliers){
  DTM <- DTM[!IDjoueur %in% idOutliersM]
  DTS <- DTS[!IDjoueur %in% idOutliersS]
  DTL <- DTL[!IDjoueur %in% idOutliersL]
}else{
  print("NOT REMOVING OUTLIERS (removeOutliers == FALSE)")
}

```

## Moyenne de la mise

```{r echo=FALSE}
DTDesc = data.table();
DTDescM = data.table();
DTDescS = data.table();
DTDescL = data.table();
DTDescM = DTM[,.(type="Moteur",mMise=mean(miseNorm)),by=IDjoueur]
DTDescS = DTS[,.(type="Sensorielle",mMise=mean(miseNorm)),by=IDjoueur]
DTDescL = DTL[,.(type="Logique",mMise=mean(miseNorm)),by=IDjoueur]
DTDesc = DTDescM;
DTDesc = rbind(DTDesc,DTDescS);
DTDesc = rbind(DTDesc,DTDescL);
p <- ggplot(DTDesc, aes(type,mMise)) + 
              xlab("Types de difficulté") + 
              ylab("Moyenne de la mise") +
              ggtitle("Isoler les stratégies critiques")
p <- p + geom_boxplot() + geom_point(shape=1) 
print(p)
outliersMMiseM <- boxplot.stats(DTDescM$mMise)$out
outliersMMiseS <- boxplot.stats(DTDescS$mMise)$out
outliersMMiseL <- boxplot.stats(DTDescL$mMise)$out
idOutliersM = DTDescM[mMise %in% outliersMMiseM]$IDjoueur
idOutliersS = DTDescS[mMise %in% outliersMMiseS]$IDjoueur
idOutliersL = DTDescL[mMise %in% outliersMMiseL]$IDjoueur
print(paste("Id out motrice mMise:",toString(idOutliersM)))
print(paste("Id out senso mMise:",toString(idOutliersS)))
print(paste("Id out logique mMise:",toString(idOutliersL)))

if(plotDiffCurvesOutliers){
  if(!length(idOutliersM )==0)
    void <- DTM[IDjoueur %in% idOutliersM,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersS) == 0)
    void <- DTS[IDjoueur %in% idOutliersS,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersL) == 0)
    void <- DTL[IDjoueur %in% idOutliersL,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurvesOutliers == FALSE")
}

if(removeOutliers){
  DTM <- DTM[!IDjoueur %in% idOutliersM]
  DTS <- DTS[!IDjoueur %in% idOutliersS]
  DTL <- DTL[!IDjoueur %in% idOutliersL]
}else{
  print("NOT REMOVING OUTLIERS (removeOutliers == FALSE)")
}
```


## Somme des mises

```{r echo=FALSE}
DTDesc = data.table();
DTDescM = data.table();
DTDescS = data.table();
DTDescL = data.table();
DTDescM = DTM[,.(type="Moteur",mMise=sum(miseNorm)),by=IDjoueur]
DTDescS = DTS[,.(type="Sensorielle",mMise=sum(miseNorm)),by=IDjoueur]
DTDescL = DTL[,.(type="Logique",mMise=sum(miseNorm)),by=IDjoueur]
DTDesc = DTDescM;
DTDesc = rbind(DTDesc,DTDescS);
DTDesc = rbind(DTDesc,DTDescL);
p <- ggplot(DTDesc, aes(type,mMise)) + 
              xlab("Types de difficulté") + 
              ylab("Somme des mises") +
              ggtitle("Isoler les stratégies critiques")
p <- p + geom_boxplot() + geom_point(shape=1) 
print(p)
outliersMMiseM <- boxplot.stats(DTDescM$mMise)$out
outliersMMiseS <- boxplot.stats(DTDescS$mMise)$out
outliersMMiseL <- boxplot.stats(DTDescL$mMise)$out
idOutliersM = DTDescM[mMise %in% outliersMMiseM]$IDjoueur
idOutliersS = DTDescS[mMise %in% outliersMMiseS]$IDjoueur
idOutliersL = DTDescL[mMise %in% outliersMMiseL]$IDjoueur
print(paste("Id out motrice sum Mise:",toString(idOutliersM)))
print(paste("Id out senso sum Mise:",toString(idOutliersS)))
print(paste("Id out logique sum Mise:",toString(idOutliersL)))

if(plotDiffCurvesOutliers){
  if(!length(idOutliersM )==0)
    void <- DTM[IDjoueur %in% idOutliersM,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersS) == 0)
    void <- DTS[IDjoueur %in% idOutliersS,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersL) == 0)
    void <- DTL[IDjoueur %in% idOutliersL,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurvesOutliers == FALSE")
}

if(removeOutliers){
  DTM <- DTM[!IDjoueur %in% idOutliersM]
  DTS <- DTS[!IDjoueur %in% idOutliersS]
  DTL <- DTL[!IDjoueur %in% idOutliersL]
}else{
  print("NOT REMOVING OUTLIERS (removeOutliers == FALSE)")
}
```

##Difficulte constatée $\sum(win)$

```{r echo=FALSE}
DTDesc = data.table();
DTDescM = data.table();
DTDescS = data.table();
DTDescL = data.table();
DTDescM = DTM[,.(type="Moteur",sWin=sum(gagnant)),by=IDjoueur]
DTDescS = DTS[,.(type="Sensorielle",sWin=sum(gagnant)),by=IDjoueur]
DTDescL = DTL[,.(type="Logique",sWin=sum(gagnant)),by=IDjoueur]
DTDesc = DTDescM;
DTDesc = rbind(DTDesc,DTDescS);
DTDesc = rbind(DTDesc,DTDescL);
p <- ggplot(DTDesc, aes(type,sWin)) + 
              xlab("Types de difficulté") + 
              ylab("Cumul des succès") +
              ggtitle("Isoler les joueurs critiques (succès)")
p <- p + geom_boxplot() + geom_point(shape=1) 
print(p)
outliersSWinM <- boxplot.stats(DTDescM$sWin)$out
outliersSWinS <- boxplot.stats(DTDescS$sWin)$out
outliersSWinL <- boxplot.stats(DTDescL$sWin)$out
idOutliersM = DTDescM[sWin %in% outliersSWinM]$IDjoueur
idOutliersS = DTDescS[sWin %in% outliersSWinS]$IDjoueur
idOutliersL = DTDescL[sWin %in% outliersSWinL]$IDjoueur
print(paste("Id out motrice sum win:",toString(idOutliersM)))
print(paste("Id out senso sum win:",toString(idOutliersS)))
print(paste("Id out logique sum win:",toString(idOutliersL)))

if(plotDiffCurvesOutliers){
  if(!length(idOutliersM)==0)
    void <- DTM[IDjoueur %in% idOutliersM,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersS) == 0)
    void <- DTS[IDjoueur %in% idOutliersS,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersL) == 0)
    void <- DTL[IDjoueur %in% idOutliersL,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurvesOutliers == FALSE")
}

if(removeOutliers){
  DTM <- DTM[!IDjoueur %in% idOutliersM]
  DTS <- DTS[!IDjoueur %in% idOutliersS]
  DTL <- DTL[!IDjoueur %in% idOutliersL]
}else{
  print("NOT REMOVING OUTLIERS (removeOutliers == FALSE)")
}

```

##Comportement stratégique (moutons sauves)

```{r echo=FALSE}
DTDesc = data.table();
DTDescM = data.table();
DTDescS = data.table();
DTDescL = data.table();
DTDescM = DTM[,.(type="Moteur",totalMoutons=max(moutons_sauves)),by=IDjoueur]
DTDescS = DTS[,.(type="Sensorielle",totalMoutons=max(moutons_sauves)),by=IDjoueur]
DTDescL = DTL[,.(type="Logique",totalMoutons=max(moutons_sauves)),by=IDjoueur]
DTDesc = DTDescM;
DTDesc = rbind(DTDesc,DTDescS);
DTDesc = rbind(DTDesc,DTDescL);
p <- ggplot(DTDesc, aes(type,totalMoutons)) + 
              xlab("Types de difficulté") + 
              ylab("Cumul des moutons gagnés") +
              ggtitle("Isoler les bons joueurs critiques (mise)")
p <- p + geom_boxplot() + geom_point(shape=1) 
print(p)
outliersMMiseM <- boxplot.stats(DTDescM$totalMoutons)$out
outliersMMiseS <- boxplot.stats(DTDescS$totalMoutons)$out
outliersMMiseL <- boxplot.stats(DTDescL$totalMoutons)$out
idOutliersM = DTDescM[totalMoutons %in% outliersMMiseM]$IDjoueur
idOutliersS = DTDescS[totalMoutons %in% outliersMMiseS]$IDjoueur
idOutliersL = DTDescL[totalMoutons %in% outliersMMiseL]$IDjoueur
print(paste("Id out motrice moutons:",toString(idOutliersM)))
print(paste("Id out senso moutons:",toString(idOutliersS)))
print(paste("Id out logique moutons:",toString(idOutliersL)))

if(plotDiffCurvesOutliers){
  if(!length(idOutliersM )==0)
    void <- DTM[IDjoueur %in% idOutliersM,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersS) == 0)
    void <- DTS[IDjoueur %in% idOutliersS,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersL) == 0)
    void <- DTL[IDjoueur %in% idOutliersL,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurvesOutliers == FALSE")
}

if(removeOutliers){
  DTM <- DTM[!IDjoueur %in% idOutliersM]
  DTS <- DTS[!IDjoueur %in% idOutliersS]
  DTL <- DTL[!IDjoueur %in% idOutliersL]
}else{
  print("NOT REMOVING OUTLIERS (removeOutliers == FALSE)")
}
```


##Comportement stratégique (moutons perdus)

```{r echo=FALSE}
DTDesc = data.table();
DTDescM = data.table();
DTDescS = data.table();
DTDescL = data.table();
DTDescM = DTM[,.(type="Moteur",totalMoutons=max(moutons_tues)),by=IDjoueur]
DTDescS = DTS[,.(type="Sensorielle",totalMoutons=max(moutons_tues)),by=IDjoueur]
DTDescL = DTL[,.(type="Logique",totalMoutons=max(moutons_tues)),by=IDjoueur]
DTDesc = DTDescM;
DTDesc = rbind(DTDesc,DTDescS);
DTDesc = rbind(DTDesc,DTDescL);
p <- ggplot(DTDesc, aes(type,totalMoutons)) + 
              xlab("Types de difficulté") + 
              ylab("Cumul des moutons perdus") +
              ggtitle("Isoler les mauvais joueurs critiques (mise)")
p <- p + geom_boxplot() + geom_point(shape=1) 
print(p)
outliersMMiseM <- boxplot.stats(DTDescM$totalMoutons)$out
outliersMMiseS <- boxplot.stats(DTDescS$totalMoutons)$out
outliersMMiseL <- boxplot.stats(DTDescL$totalMoutons)$out
idOutliersM = DTDescM[totalMoutons %in% outliersMMiseM]$IDjoueur
idOutliersS = DTDescS[totalMoutons %in% outliersMMiseS]$IDjoueur
idOutliersL = DTDescL[totalMoutons %in% outliersMMiseL]$IDjoueur
print(paste("Id out motrice moutons:",toString(idOutliersM)))
print(paste("Id out senso moutons:",toString(idOutliersS)))
print(paste("Id out logique moutons:",toString(idOutliersL)))

if(plotDiffCurvesOutliers){
  if(!length(idOutliersM )==0)
    void <- DTM[IDjoueur %in% idOutliersM,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersS) == 0)
    void <- DTS[IDjoueur %in% idOutliersS,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersL) == 0)
    void <- DTL[IDjoueur %in% idOutliersL,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurvesOutliers == FALSE")
}

if(removeOutliers){
  DTM <- DTM[!IDjoueur %in% idOutliersM]
  DTS <- DTS[!IDjoueur %in% idOutliersS]
  DTL <- DTL[!IDjoueur %in% idOutliersL]
}else{
  print("NOT REMOVING OUTLIERS (removeOutliers == FALSE)")
}
```


##Comportement stratégique (alternance win fail)

```{r echo=FALSE}
DTDesc = data.table();
DTDescM = data.table();
DTDescS = data.table();
DTDescL = data.table();
DTDescM = DTM[,.(type="Moteur",cumul=max(cumulDeltaMise)),by=IDjoueur]
DTDescS = DTS[,.(type="Sensorielle",cumul=max(cumulDeltaMise)),by=IDjoueur]
DTDescL = DTL[,.(type="Logique",cumul=max(cumulDeltaMise)),by=IDjoueur]
DTDesc = DTDescM;
DTDesc = rbind(DTDesc,DTDescS);
DTDesc = rbind(DTDesc,DTDescL);
p <- ggplot(DTDesc, aes(type,cumul)) + 
              xlab("Types de difficulté") + 
              ylab("Cumul du delta des mises") +
              ggtitle("Isoler la stratégie alernance échec/succès")
p <- p + geom_boxplot() + geom_point(shape=1)
print(p)
outliersMMiseM <- boxplot.stats(DTDescM$cumul)$out
outliersMMiseS <- boxplot.stats(DTDescS$cumul)$out
outliersMMiseL <- boxplot.stats(DTDescL$cumul)$out
idOutliersM = DTDescM[cumul %in% outliersMMiseM]$IDjoueur
idOutliersS = DTDescS[cumul %in% outliersMMiseS]$IDjoueur
idOutliersL = DTDescL[cumul %in% outliersMMiseL]$IDjoueur
print(paste("Id out motrice moutons:",toString(idOutliersM)))
print(paste("Id out senso moutons:",toString(idOutliersS)))
print(paste("Id out logique moutons:",toString(idOutliersL)))

if(plotDiffCurvesOutliers){
  if(!length(idOutliersM )==0)
    void <- DTM[IDjoueur %in% idOutliersM,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersS) == 0)
    void <- DTS[IDjoueur %in% idOutliersS,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
  if(!length(idOutliersL) == 0)
    void <- DTL[IDjoueur %in% idOutliersL,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurvesOutliers == FALSE")
}

if(removeOutliers){
  DTM <- DTM[!IDjoueur %in% idOutliersM]
  DTS <- DTS[!IDjoueur %in% idOutliersS]
  DTL <- DTL[!IDjoueur %in% idOutliersL]
}else{
  print("NOT REMOVING OUTLIERS (removeOutliers == FALSE)")
}
```


```{r echo=FALSE}
#creation de la table totale
DT <- data.table()
if(useLogique) DT <- rbind(DT,DTL)
if(useMotrice) DT <- rbind(DT,DTM)
if(useSensorielle) DT <- rbind(DT,DTS)

#supprimer le debut ou la fin
if(removeTenFirst)
  DT <- removeHeadTail(DT,10);
```


Il reste , **`r length(unique(DTM$IDjoueur))`** joueurs en moteur, **`r length(unique(DTL$IDjoueur))`** en logique et **`r length(unique(DTL$IDjoueur))`** joueurs en senso.

# Des essais...

```{r echo=FALSE}

if(TEST){
  
  #hard easy guigui
  DTParam <- DTL
  res <- numeric(10)
  nb <- numeric(10)
  diffVec <- numeric(10)
  i = 1;
  while(i<=10){
    diff=i/10;
    DTLoc = DTParam[which(estDiff >= diff-0.1 & estDiff < diff+0.1)]
    res[i] = mean(DTLoc$miseNorm);
    nb[i] = nrow(DTLoc);
    diffVec[i] = diff;
    i=i+1
    #print(shapiro.test(DTLoc$miseNorm));
    #print(hist(DTLoc$miseNorm))
  }
  
  print(res)
  print(nb)
  
  testPlot = data.table(x=diffVec);
  testPlot$y = res;
  
  plot(testPlot,ylim=c(0, 1),xlim=c(0, 1))
  abline(a=1,b=-1)
  plot(DTL$evalDiff)
  
  #-------- pour le Wilcox test
  #2 valeurs : la mise observée (miseNorm) par rapport à la mise attendue sur un même niveau de difficulté
  #Il faut donc renseigner pour chaque niveau de difficulté, la mise attendue, soit la droite tracée
  #
  
  
  DTLoc <- DTS[action_de_jeu==8]
  DTLoc <- DTL
  DTLoc <- DTL[IDjoueur != "3t1l09dyk"]
  DTLoc$newErr <- DTLoc$miseNorm - DTLoc$gagnant;
  #fit <- glm(DTLoc$newErr ~ DTLoc$resLisse + DTLoc$difficulty, family = "binomial"(link = "logit"));
  fit <- glm(newErr ~ resLisse + difficulty, data=DTLoc);
  fit <- glm(newErr ~  nbWin + nbFail + difficulty, data=DTLoc);
  
  
  fit <- lmer(gagnant ~ resLisse +  (difficulty | IDjoueur), data=DTLoc);
  
  #residualisation
  test = lm(resLisse ~ difficulty,data=DTLoc);
  summary(test)
  DTLoc$rResLisse = residuals(test)
  
  fit <- lmer(miseNorm ~ rResLisse + difficulty + (1 | IDjoueur), data=DTLoc);
  fit <- lm(miseNorm ~ rResLisse + difficulty, data=DTLoc);
  
  
  require(lme4)
  
  fit <- lmer(miseNorm ~ resLisse + difficulty + (1 | IDjoueur), data=DTLoc);
  
  
  require(languageR)
  head(DTLoc)
  collin.fnc(DTLoc,c(7,14))$cnumber
  
  
  fit <- glm(miseNorm ~ nbWin + nbFail + difficulty, data=DTLoc);
  
  fit <- lm(mise ~ difficulty + nbFail + nbWin,  data=DTLoc);
  fit <- glm(miseBin ~ difficulty, family="binomial"(link = "logit"),  data=DTLoc);
  
  hist(DTLoc$estDiff,breaks=30)
  
  
  dummy_df <- data.frame(DTLoc$difficulty, DTLoc$resLisse, DTLoc$rResLisse)
  correl_dummy_df <- round(cor(dummy_df, use = "pair"), 2)
  
  
  fit<- glmer(perdant ~ difficulty + sexe + (1 | IDjoueur), data=DTL,family="binomial"(link="logit"))
  fit<- lmer(perdant ~ difficulty + (1 | IDjoueur), data=DTS)
  fit<- glm(perdant ~ difficulty , data=DTL,family="binomial"(link="logit"))
  fit<- glm(perdant ~ difficulty,data=DTL )
  
  
  #resumé
  summary(fit)
  #normality of residuals
  test <- residuals(fit);
  hist(test,breaks=40)
  shapiro.test(test);
  qqPlot(residuals(fit))
  
  #homoscedasticity
  ncvTest(fit)
  #colinear predictors
  vif(fit)
  
  library(MASS)
  sresid <- studres(fit)
  qqnorm(residuals(fit))
  hist(sresid, freq=FALSE, main="Distribution of Studentized Residuals")
  
  require(MuMIn)
  require(lme4)
  DTLoc$erreurMise = DTLoc$miseNorm - DTLoc$gagnant;
  fit1 <- lmer(miseNorm ~ resLisse + difficulty + (1 | IDjoueur), data=DTLoc);
  fit2 <- lmer(miseNorm ~ difficulty + (1 | IDjoueur), data=DTLoc);
  fit1 <- lmer(miseNorm ~ resLisse + (1 | IDjoueur), data=DTLoc);
  r.squaredGLMM(fit1)
  r.squaredGLMM(fit2)
  
  summary(fit1)
  summary(fit2)
  
  #============ trucs thomas
  #echec au lieu de succes pour diff c'est mieux
  DTLoc$perdant <- 1-DTLoc$gagnant;
  
  #This is FAIL: si on vire les mises, le modèle est parfait
  #DTLoc$mise = 0;
  
  #normalisation de la mise
  DTLoc$miseNorm <- DTLoc$mise / 7;
  
  #difficulte évaluée par le joueur
  DTLoc$evalDiff <- 1 - DTLoc$miseNorm;
  
  #difficulte evaluee par le joueur : logit approach
  DTLoc[,miseBin := 0][mise >= 4, miseBin := 1]
  DTLoc[,evalDiffBin := 1][mise >= 4, evalDiffBin := 0]
  
  DTLoc$newErr <- DTLoc$miseNorm - DTLoc$gagnant;
  DTLoc$erreurMise = DTLoc$miseNorm - DTLoc$gagnant;
  
  #On ajoute une colonne de la difficulte estimee, a partir d'un 
  #logit de la difficulte supposée sur l'échec constaté
  mylogit <- glm(perdant ~ difficulty, data = DTLoc, family = "binomial"(link = "logit"))
  print(summary(mylogit));
  sample = data.frame(difficulty=DTLoc$difficulty);
  DTLoc$estDiff =  predict(mylogit, newdata = sample, type = "response");
  
  #=================== hard/easy effect
  #------------------ tous les jeux
  maxEstDiff <- max(DTLoc$estDiff)
  minEstDiff <- min(DTLoc$estDiff)
  intervalEstDiff <- (maxEstDiff - minEstDiff)/10
  
  #------------------ difficulté logique
  DTLocL <- DTLoc[nom_du_jeu == "Logique2"]
  maxEstDiffL <- max(DTLocL$estDiff)
  minEstDiffL <- min(DTLocL$estDiff)
  intervalEstDiffL <- (maxEstDiffL - minEstDiffL)/10
  
  ggplot(DTLocL, aes(x=factor(estDiff), y=evalDiff)) + 
    stat_summary(fun.y="mean", geom="bar") +
    stat_summary(aes(label=round(..y..,2)), fun.y=mean, geom="text", size=6,
             vjust = -0.5)
  
  ggplot(DTL, aes(x=estDiff, y=evalDiff)) + 
    stat_summary(fun.y="mean", geom="bar") +
    stat_summary(aes(label=round(..y..,2)), fun.y=mean, geom="text", size=6,
             vjust = -0.5) +
    geom_abline(intercept=-1, color = "red", size=1)
  
  #------------------ difficulté sensorielle
  DTLocS <- DTLoc[nom_du_jeu == "Sensoriel"]
  maxEstDiffS <- max(DTLocS$estDiff)
  minEstDiffS <- min(DTLocS$estDiff)
  ggplot(DTLocS, aes(x=factor(estDiff), y=evalDiff)) + 
    stat_summary(fun.y="mean", geom="bar") +
    stat_summary(aes(label=round(..y..,2)), fun.y=mean, geom="text", size=6,
             vjust = -0.5)
  
  ggplot(DTS, aes(x=estDiff, y=evalDiff)) + 
    stat_summary(fun.y="mean", geom="bar") +
    stat_summary(aes(label=round(..y..,2)), fun.y=mean, geom="text", size=6,
             vjust = -0.5)
  
  #------------------ difficulté motrice
  DTLocM <- DTLoc[nom_du_jeu == "Motrice"]
  maxEstDiffM <- max(DTLocM$estDiff)
  minEstDiffM <- min(DTLocM$estDiff)
  ggplot(DTLocM, aes(x=factor(estDiff), y=evalDiff)) + 
    stat_summary(fun.y="mean", geom="bar") +
    stat_summary(aes(label=round(..y..,2)), fun.y=mean, geom="text", size=6,
             vjust = -0.5)
  
  ggplot(DTM, aes(x=estDiff, y=evalDiff)) + 
    stat_summary(fun.y="mean", geom="bar") +
    stat_summary(aes(label=round(..y..,2)), fun.y=mean, geom="text", size=6,
             vjust = -0.5)
  
  
  DTLocEvalDiffLogique <- DTLoc[c(nom_du_jeu == "Logique2",evalDiff)]
  
  analyseHardEasyEffect <- function(DTParam){
  res <- numeric(11)
  coef <- numeric(11)
  nb <- numeric(11)
  nb2 <- numeric(11)
  pv1 <- numeric(11)
  pv2 <- numeric(11)
  dObj <- numeric(11)
  i = 0;
  while(i<=10){
    diff=i/10;
    print(diff)
    DTLoc = DTParam[which(difficulty >= diff-0.01 & difficulty <= diff+0.01 & action_de_jeu > 2)]
    
    DTLoc$miseBin = ifelse(DTLoc$mise>4, 1, 0);
    # DTLoc[,miseBin:= -1]; 
    # DTLoc[mise > 4,miseBin := 1];
    # DTLoc[mise < 4,miseBin := 0];
    # DTLoc = DTLoc[miseBin != -1];
    # 
    if(nrow(DTLoc) > 30){
       plot(x=DTLoc$resLisse, y=DTLoc$miseNorm, main=paste(diff,signif(unique(DTLoc$estDiff),digits=2)))
      # 
      # fit <- glm(DTLoc$miseNorm ~ DTLoc$resLisse);
      # 
      # 
      # fitg <- glm(miseBin ~ resLisse, data = DTLoc, family = "binomial"(link = "logit"))
      # sample = data.frame(resLisse=seq(0, 1, 0.05))
      # newres = predict(fitg, newdata = sample, type = "response")
      # points(x=sample$resLisse,y=newres,col="red")
      # print(summary(fitg))
      # abline(a =fit$coefficients[1], b=fit$coefficients[2], col="green")
      # res[i+1] = signif(fit$coefficients[2],digits=2);
      # 
      # #print(unlist(summary(fit)));
      # pv1[i+1] = echoPValue(unlist(summary(fitg))$coefficients7)
      # pv2[i+1] = echoPValue(unlist(summary(fitg))$coefficients8)
      
      fit <- lm(DTLoc$miseNorm ~ DTLoc$resLisse);
      abline(a =fit$coefficients[1], b=fit$coefficients[2], col="green")
      print(summary(fit))
      print(qqPlot(residuals(fit)))
      pv1[i+1] = echoPValue(summary(fit)$coefficients[2,4]);
      pv2[i+1] = echoPValue(shapiro.test(residuals(fit))$p.value);
      res[i+1] =  signif(summary(fit)$r.squared,digits=2);
      coef[i+1] =  signif(summary(fit)$coefficients[2,1],digits=2)
      
      
      #print(echoPValue(summary(fit)$coefficients[,4]))
      #print(summary(fit)$r.squared)
      print("next")

      
      
    }else{
      res[i+1] = NA;
      pv1[i+1] = NA;
      pv2[i+1] = NA;
      coef[i+1] = NA;
    }
    
    nb[i+1] = nrow(DTLoc);
    nb2[i+1] = length(unique(DTLoc$IDjoueur))
    dObj[i+1] = DTLoc$estDiff[1];
  
    i=i+1
  }
  
  resTable = data.table(NbObservations = nb);
#  resTable[,NbObservations := nb];
  resTable[,DiffObj := dObj];
  resTable[,NbJoueurs := nb2];
  resTable[,Coef := coef];
  resTable[,R2 := res];
  resTable[,pValueModele := pv1];
  resTable[,normResidus := pv2];
  

  return(resTable)
}
  
  
  
  #=================== mise par rapport à la difficulté
  model <- lmer(DTLoc$mise ~ DTLoc$difficulty + (1 | DTLoc$IDjoueur))
  summary(model)
  r.squaredGLMM(model)
  predict(model)
  
  #------------------ mise par rapport à la difficulté logique
  DTLocL <- DTLoc[nom_du_jeu == "Logique2"]
  model <- lmer(DTLocL$mise ~ DTLocL$difficulty + (1 | DTLocL$IDjoueur))
  summary(model)
  r.squaredGLMM(model)
  predict(model)
  
  #------------------ mise par rapport à la difficulté motrice
  DTLocM <- DTLoc[nom_du_jeu == "Motrice"]
  model <- lmer(DTLocM$mise ~ DTLocM$difficulty + (1 | DTLocM$IDjoueur))
  summary(model)
  r.squaredGLMM(model)
  predict(model)
  
  #------------------ mise par rapport à la difficulté sensorielle
  DTLocS <- DTLoc[nom_du_jeu == "Sensoriel"]
  model <- lmer(DTLocS$mise ~ DTLocS$difficulty + (1 | DTLocS$IDjoueur))
  summary(model)
  r.squaredGLMM(model)
  predict(model)
  
  
  
  # install.packages("sjPlot")
  # install.packages("arm")
  # require(sjPlot)
  # require(arm)
  # sjp.lmer(model)
  # 
  # plot(x=DTLoc$erreurMise, y=DTLoc$difficulty)
  # abline(h=mean(DTLoc$erreurMise),col = "blue", lwd = 2)
  # 
  # ggplot(data=DTLoc, aes(miseNorm,difficulty))
  # ggplot(model)
  # #install.packages("multcomp")
  # library(multcomp)
  # tmp <- as.data.frame(confint(glht(model))$confint)
  # tmp$Comparison <- rownames(tmp)
  # ggplot(tmp, aes(x = Comparison, y = Estimate, ymin = lwr, ymax = upr)) + geom_errorbar() + geom_point()
  # 
  # 
  # install.packages("ggplot2")
  # library(ggplot2)
  
  #=================== erreur mise dans le temps
  model <- lmer(DTLoc$erreurMise ~ DTLoc$action_de_jeu + (1 | DTLoc$IDjoueur))
  summary(model) #nope
  r.squaredGLMM(model)
  plot(DTLoc$erreurMise ~ DTLoc$action_de_jeu)
  
  #=================== erreur mise selon profil de joueur de jeu vidéo du participant
  model <- lmer(DTLoc$erreurMise ~ DTLoc$maxProfilJoueurJeuVideo + (1 | DTLoc$IDjoueur))
  model <- aov(DTLoc$erreurMise ~ DTLoc$maxProfilJoueurJeuVideo)
  summary(model) #nope
  r.squaredGLMM(model)
  
  #------------------ erreur mise par rapport à la difficulté (selon profil jeu vidéo gamer du participant)
  DTLocGamer <- DTLoc[maxProfilJoueurJeuVideo>=3]
  model <- lmer(DTLocGamer$erreurMise ~ DTLocGamer$difficulty + (1 | DTLocGamer$IDjoueur))
  summary(model)
  r.squaredGLMM(model)
  
  #------------------ erreur mise par rapport à la difficulté (selon profil jeu vidéo non-gamer du participant)
  DTLocNoGamer <- DTLoc[maxProfilJoueurJeuVideo<3]
  model <- lmer(DTLocNoGamer$erreurMise ~ DTLocNoGamer$difficulty + (1 | DTLocNoGamer$IDjoueur))
  summary(model) #***, mais effet ridicule et R2 léger
  r.squaredGLMM(model)
  
  #=================== erreur mise selon profil de joueur de jeu de plateau du participant
  model <- lmer(DTLoc$erreurMise ~ DTLoc$maxProfilJoueurJeuPlateau + (1 | DTLoc$IDjoueur))
  model <- aov(DTLoc$erreurMise ~ DTLoc$maxProfilJoueurJeuPlateau)
  summary(model) #nope
  r.squaredGLMM(model)
  
  #=================== erreur mise selon profil de joueur de jeu d'argent du participant
  model <- lmer(DTLoc$erreurMise ~ DTLoc$maxProfilJoueurJeuArgent + (1 | DTLoc$IDjoueur))
  model <- aov(DTLoc$erreurMise ~ DTLoc$maxProfilJoueurJeuArgent)
  summary(model) #nope
  r.squaredGLMM(model)
  
  #=================== erreur mise selon profil risquophobe/risquophile du participant
  model <- lmer(DTLoc$erreurMise ~ DTLoc$sumProfilRA + (1 | DTLoc$IDjoueur))
  summary(model) #pas d'impact lié au profil risquophobe/phile
  r.squaredGLMM(model)
  
  #------------------ erreur mise par rapport à la difficulté (selon profil risquophobe du participant)
  DTLocRisk <- DTLoc[sumProfilRA>=6]
  model <- lmer(DTLocRisk$erreurMise ~ DTLocRisk$difficulty + (1 | DTLocRisk$IDjoueur))
  summary(model) #rassurant, être risquophobe n'a pas d'impact, on peut garder les données
  r.squaredGLMM(model)
  
  #------------------ erreur mise par rapport à la difficulté (selon profil risquophile du participant)
  DTLocNoRisk <- DTLoc[sumProfilRA<=5]
  model <- lmer(DTLocNoRisk$erreurMise ~ DTLocNoRisk$difficulty + (1 | DTLocNoRisk$IDjoueur))
  summary(model) #rassurant, être risquophile n'a pas d'impact, on peut garder les données
  r.squaredGLMM(model)
  
  #=================== erreur mise selon sexe du participant
  model <- aov(DTLoc$erreurMise ~ DTLoc$sexe)
  summary(model) #pas d'impact lié au sexe
  r.squaredGLMM(model)
  
  #------------------ erreur mise par rapport à la difficulté (selon sexe du participant)
  DTLocWomen <- DTLoc[sexe==1]
  model <- lmer(DTLocWomen$erreurMise ~ DTLocWomen$difficulty + (1 | DTLocWomen$IDjoueur))
  summary(model) 
  r.squaredGLMM(model) #r2 non révélateur
  
  DTLocMen <- DTLoc[sexe==0]
  model <- lmer(DTLocMen$erreurMise ~ DTLocMen$difficulty + (1 | DTLocMen$IDjoueur))
  summary(model)
  r.squaredGLMM(model) #r2 non révélateur
  
  #=================== erreur mise selon niveau d'étude du participant
  #A REPRENDRE
  # DTLocBac2Plus <- DTLoc[niveauEtude>=4]
  # model <- lmer(DTLocBac2Plus$erreurMise ~ DTLocBac2Plus$meanProfilJoueur + (1 | DTLocBac2Plus$IDjoueur))
  # summary(model) #pas d'impact lié à un niveau d'étude >= à Bac+2
  # 
  # DTLocBacPlus <- DTLoc[niveauEtude>=3]
  # model <- lmer(DTLocBacPlus$erreurMise ~ DTLocBacPlus$meanProfilJoueur + (1 | DTLocBacPlus$IDjoueur))
  # summary(model) #pas d'impact lié à un niveau d'étude >= à Bac
  # 
  # DTLocNoBac <- DTLoc[niveauEtude<3]
  # model <- lmer(DTLocNoBac$erreurMise ~ DTLocNoBac$meanProfilJoueur + (1 | DTLocNoBac$IDjoueur))
  # summary(model) #pas d'impact lié à un niveau d'étude < au Bac (rassurant, vu le nombre de participants)
  # 
  #=================== erreur mise selon âge du participant
  #A REPRENDRE
  # DTLocMoins15 <- DTLoc[age<=15]
  # model <- lmer(DTLocMoins15$erreurMise ~ DTLocMoins15$meanProfilJoueur + (1 | DTLocMoins15$IDjoueur))
  # summary(model) #pas d'impact pour les participants de 15ans ou moins (rassurant, c'est la majorité des joueurs)
  # 
  # DTLocPlus15 <- DTLoc[age>15]
  # model <- lmer(DTLocPlus15$erreurMise ~ DTLocPlus15$meanProfilJoueur + (1 | DTLocPlus15$IDjoueur))
  # summary(model) #pas d'impact pour les participants strictement > à 15ans
  # 
  
  #=================== autres tests
  fit <- glm(miseBin ~ nbWin + nbFail + difficulty, data=DTLoc);
  fit <- glm(miseNorm ~ lastWin + lastFail + difficulty, data=DTLoc);
  confint(fit)
  fit <- glm(miseNorm ~ resLisse + difficulty, data=DTLoc);
  
  hist(DTLoc$resLisse)
  
  summary(fit)
  dotplot(ranef(fit))
  
  
  ran = as.data.table()
  hist(class(ranef(fit)))
  ranef(fit)
  fixef(fit)
  length(unlist((ranef(fit))))
  
  plot(fit, which=1)

}

# DTLoc1 = DTL;
# 
# res <- numeric(11)
# nb <- numeric(11)
# i = 0;
# while(i<=10){
#   diff=i/10;
#   print(diff)
#   DTLoc = DTLoc1[which(difficulty >= diff-0.01 & difficulty <= diff+0.01  & action_de_jeu > 5)]
#   if(nrow(DTLoc) > 20){
#     plot(x=DTLoc$resLisse, y=DTLoc$erreurDiffConfiance, main=paste(diff,signif(unique(DTLoc$estDiff),digits=2)))
#     fit <- glm(DTLoc$erreurDiffConfiance ~ DTLoc$resLisse);
#     DTLoc$miseBin = ifelse(DTLoc$mise>4, 1, 0)
#     fitg <- glm(miseBin ~ resLisse, data = DTLoc, family = "binomial"(link = "logit"))
#     sample = data.frame(resLisse=seq(0, 1, 0.05))
#     newres = predict(fitg, newdata = sample, type = "response")
#     points(x=sample$resLisse,y=newres,col="red")
#     print(summary(fitg))
#     abline(a =fit$coefficients[1], b=fit$coefficients[2], col="green")
#     res[i+1] = fit$coefficients[2];
#     nb[i+1] = nrow(DTLoc);
#   }else{
#     res[i+1] = NA;
#   }
# 
#   i=i+1
# }
# print(nb)
# print(res)

analyseParDifficute <- function(DTParam){
  res <- numeric(11)
  coef <- numeric(11)
  nb <- numeric(11)
  nb2 <- numeric(11)
  pv1 <- numeric(11)
  pv2 <- numeric(11)
  dObj <- numeric(11)
  i = 0;
  while(i<=10){
    diff=i/10;
    print(diff)
    DTLoc = DTParam[which(difficulty >= diff-0.01 & difficulty <= diff+0.01  & action_de_jeu > 2)]
    
    DTLoc$miseBin = ifelse(DTLoc$mise>4, 1, 0);
    # DTLoc[,miseBin:= -1]; 
    # DTLoc[mise > 4,miseBin := 1];
    # DTLoc[mise < 4,miseBin := 0];
    # DTLoc = DTLoc[miseBin != -1];
    # 
    if(nrow(DTLoc) > 30){
       plot(x=DTLoc$resLisse, y=DTLoc$miseNorm, main=paste(diff,signif(unique(DTLoc$estDiff),digits=2)))
      # 
      # fit <- glm(DTLoc$miseNorm ~ DTLoc$resLisse);
      # 
      # 
      # fitg <- glm(miseBin ~ resLisse, data = DTLoc, family = "binomial"(link = "logit"))
      # sample = data.frame(resLisse=seq(0, 1, 0.05))
      # newres = predict(fitg, newdata = sample, type = "response")
      # points(x=sample$resLisse,y=newres,col="red")
      # print(summary(fitg))
      # abline(a =fit$coefficients[1], b=fit$coefficients[2], col="green")
      # res[i+1] = signif(fit$coefficients[2],digits=2);
      # 
      # #print(unlist(summary(fit)));
      # pv1[i+1] = echoPValue(unlist(summary(fitg))$coefficients7)
      # pv2[i+1] = echoPValue(unlist(summary(fitg))$coefficients8)
      
      fit <- lm(DTLoc$miseNorm ~ DTLoc$resLisse);
      abline(a =fit$coefficients[1], b=fit$coefficients[2], col="green")
      print(summary(fit))
      print(qqPlot(residuals(fit)))
      pv1[i+1] = echoPValue(summary(fit)$coefficients[2,4]);
      pv2[i+1] = echoPValue(shapiro.test(residuals(fit))$p.value);
      res[i+1] =  signif(summary(fit)$r.squared,digits=2);
      coef[i+1] =  signif(summary(fit)$coefficients[2,1],digits=2)
      
      
      #print(echoPValue(summary(fit)$coefficients[,4]))
      #print(summary(fit)$r.squared)
      print("next")

      
      
    }else{
      res[i+1] = NA;
      pv1[i+1] = NA;
      pv2[i+1] = NA;
      coef[i+1] = NA;
    }
    
    nb[i+1] = nrow(DTLoc);
    nb2[i+1] = length(unique(DTLoc$IDjoueur))
    dObj[i+1] = DTLoc$estDiff[1];
  
    i=i+1
  }
  
  resTable = data.table(NbObservations = nb);
#  resTable[,NbObservations := nb];
  resTable[,DiffObj := dObj];
  resTable[,NbJoueurs := nb2];
  resTable[,Coef := coef];
  resTable[,R2 := res];
  resTable[,pValueModele := pv1];
  resTable[,normResidus := pv2];
  

  return(resTable)
}


print("Logique")
resLog = analyseParDifficute(DTL);
print("Motrice")
resMot = analyseParDifficute(DTM);
print("Senso")
resSenso = analyseParDifficute(DTS);




# 
# DTS2 = DTS[which(action_de_jeu > 10)]
# hist(DTS2$difficulty)
# DTS2 = DTS[which(difficulty == 0.3 & action_de_jeu > 10)]
# hist(DTS2$resLisse)
# hist(DTS2$erreurDiffConfiance)
# shapiro.test(DTS2$resLisse)
# shapiro.test(DTS2$mise)
# qqnorm(DTS2$resLisse)
# qqnorm(DTS2$mise)
# 
# lienErreurEvalDiffFailsRepetes(DTS2)
# lienErreurEvalDiffFailsRepetes(DTS2,FALSE)
# 
# DTLoc = DTS2;
# plot(x=DTLoc$resLisse, y=DTLoc$mise)
# fit <- glm(DTLoc$mise ~ DTLoc$resLisse);
# abline(a =fit$coefficients[1], b=fit$coefficients[2], col="green")
# 
# fit <- lm(mise ~ resLisse, data=DTS2);
# plot(fit)
# summary(fit);
```
##Resume des essais 

```{r echo=FALSE}
print("Logique")
print(resLog);
print("Motrice")
print(resMot);
print("Senso")
print(resSenso );
```


# Estimation de l'excès et du manque de confiance
<p align = "justify" >&nbsp;&nbsp; Une deuxième étape consiste à vérifier si l'évolution de la difficulté du jeu a un impact sur la difficulté ressentie par les joueurs, la mise servant ici de référence. L'analyse précédente a permis de pouvoir obtenir la difficulté réelle de chaque jeu, nouvelle variable qui sert dorénavant de mesure de base pour observer les variations de la difficulté ressentie par le joueur.</p>
&nbsp;&nbsp; Deux nouvelles mesures sont ajoutées :

<p align = "justify" >* Le nombre d'échecs consécutifs du joueur (noté **nbFail**), qui permet de vérifier sa progression. Un échec faisant revenir le joueur à une tâche de difficulté moindre ; plus le joueur perd, plus la difficulté du jeu baisse.</p>

<p align = "justify" >* Le nombre de succès consécutifs du joueur (noté **nbWin**), où un succès entraîne une augmentation de la difficulté au tour suivant ; autrement dit, plus le joueur gagne, plus la difficulté augmente.</p> 

<p align = "justify" >&nbsp;&nbsp; Dans les deux cas, il n'y a modification de la progression de la difficulté que si le statut de réussite du joueur change (de gagnant à perdant, de perdant à un gagnant).</p>

<p align = "justify" >&nbsp;&nbsp; La mise, basée sur une échelle de Likert de 1 à 7 points, permet d'obtenir une appréciation pour chaque tour de jeu de la difficulté ressentie par le joueur (et non de la difficulté réelle de la tâche). La mise est donc normalisée, entre 0 et 1, à laquelle on retranche la difficulté réelle calculée en amont. Cette différence nous permet d'obtenir l'erreur d'appréciation de la difficulté du jeu, cadrée ici entre -1 et +1.</p>

<p align = "justify" >&nbsp;&nbsp; Les figures suivantes présentent ainsi, pour tous les jeux puis pour chacun d'entre-eux (et donc pour chaque type de difficulté), le nombre d'échecs consécutifs (nbFail) et de succès consécutifs (nbWin) par rapport à l'erreur d'appréciation de la difficulté par le joueur. Chaque figure est accompagnée des conclusions d'une analyse de la variance (ANOVA) et de la régression linéaire, tracée en vert. La courbe rouge correspond aux valeurs médianes, les bleues mesurent quant à elles deux fois l'écart type, signifiant le faible nombre de participants. Malgré cette limite, il est possible de commenter ces données, en attendant de les confronter à celles qui vont être récupérées sur une population plus importante lors des expérimentations finales.</p>

## Tous jeux confondus
<p align = "justify" >&nbsp;&nbsp; Pour l'ensemble des données tirées des trois jeux, on observe dans le cas d'échecs consécutifs une sur-estimation de la difficulté du jeu, laissant à penser que le joueur développe un manque de confiance quant à ses chances de réussir. A l'inverse, lorsque le joueur cumule les succès, il aurait tendance à sous-estimer la difficulté du jeu, bien que l'effet soit moins visible pour les échecs. Le manque de données pour ce cas peut en être à l'origine.</p>

### Nombre d'échecs consécutifs

```{r echo=FALSE}
#lien erreur d'eval diff (exces confiance ?) et fails ou succes répétés
fit <- lienErreurEvalDiffFailsRepetes(DT,TRUE,"Tous les jeux")
pvalDTFails = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTFails);
```

### Nombre de réussites consécutives

```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DT,FALSE,"Tous les jeux")
pvalDTWins = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTWins);
```

### Indice de confiance lissé

```{r echo=FALSE}
fit <- lienErreurEvalDiffResLisse(DT,"Tous les jeux")
pvalDTLisse = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTLisse);

```

## Difficulté logique
<p align = "justify" >&nbsp;&nbsp; Indépendamment pour le jeu de déduction, le nombre d'échecs consécutifs ne semble pas avoir un trop important impact sur l'estimation de la difficulté par le joueur, et ne conduirait pas à un manque de confiance. Une hypothèse serait que, face à ce type de difficulté, le joueur aurait plus de temps pour apprécier son aptitude à résoudre le problème donné et donc une meilleure appréciation de la difficulté. A l'inverse, il ferait preuve d'un léger excès de confiance dans le cas de succès répétés. De nouvelles données permettront de mieux cerner ces comportements.</p>

```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DTL,TRUE,"Difficulté logique")
pvalDTLFails = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTLFails);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>
```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DTL,FALSE,"Difficulté logique")
pvalDTLWins = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTLWins);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>

```{r echo=FALSE}
fit <- lienErreurEvalDiffResLisse(DTL,"Difficulté logique")
pvalDTLLisse = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTLLisse);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>

### Courbes de difficulte
```{r echo=FALSE}
if(plotDiffCurves){
  void <- DTL[,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurves == FALSE")
}
```


## Difficulté motrice
<p align = "justify" >&nbsp;&nbsp; Le jeu d'adresse ne montre qu'une légère sous-estimation de la difficulté dans le cas d'échecs consécutifs, qui tendrait à disparaître. Les résultats sont plus probants dans le cas de succès consécutifs. Là aussi, de nouvelles données permettront d'étoffer cette analyse, mais une modification de la conception du jeu pourrait permettre d'isoler les comportements. De tous, le jeu d'adresse est le plus rapide à réaliser (les tours de jeu s'enchaînant vite), ce qui peut entraîner une plus grande inattention de la part du joueur (là où la tâche de perception visuelle en requiert énormément, et celle de logique pouvant provoquer une rapide saturation cognitive).</p>

```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DTM,TRUE,"Difficulté motrice")
pvalDTMFails = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTMFails);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>
```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DTM,FALSE,"Difficulté motrice")
pvalDTMWins = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTMWins);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>
```{r echo=FALSE}
fit <- lienErreurEvalDiffResLisse(DTM,"Difficulté motrice")
pvalDTMLisse = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTMLisse);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>


### Courbes de difficulte
```{r echo=FALSE}
if(plotDiffCurves){
  void <- DTM[,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurves == FALSE")
}
```

## Difficulté sensorielle
<p align = "justify" >&nbsp;&nbsp; Reste le jeu de perception visuelle, dont les résultats semblent le mieux confirmer nos hypothèses, mettant en évidence un excès de confiance de la part du joueur lorsqu'il cumule les succès, et un manque de confiance lorsqu'il cumule les échecs.</p>

```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DTS,TRUE,"Difficulté sensorielle")
pvalDTSFails = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTSFails);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>

```{r echo=FALSE}
fit <- lienErreurEvalDiffFailsRepetes(DTS,FALSE,"Difficulté sensorielle")
pvalDTSWins = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTSWins);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>
```{r echo=FALSE}
fit <- lienErreurEvalDiffResLisse(DTS,"Difficulté sensorielle")
pvalDTSLisse = unlist(summary(fit))["Pr(>F)1"]
print("pvalue anova")
  echoPValue(pvalDTSLisse);
```

```{r fig.width=4, fig.height=4,echo=FALSE,out.extra=' style="float:left"'}
if(plotLinModels){
  plot(fit);
}else{
  print("plotLinModels == FALSE")
}
```
<div style="clear:both">&nbsp;</div>

### Courbes de difficulte
```{r echo=FALSE}
if(plotDiffCurves){
  void <- DTS[,{plotCurves(action_de_jeu,difficulty,evalDiff,estDiff,resLisse,IDjoueur,nbWin,nbFail,erreurDiffConfiance,miseNorm,IDjoueur);NULL},by=.(IDjoueur)]
}else{
  print("plotDiffCurves == FALSE")
}
```

# Summary des pvalues

- All lissee `r echoPValue(pvalDTLisse);`
- Motrice lissee `r echoPValue(pvalDTMLisse)`
- Senso lissee `r echoPValue(pvalDTSLisse)`
- Logique lissee `r echoPValue(pvalDTLLisse)`

- All NBWin `r echoPValue(pvalDTWins)`
- Motrice NBWin `r echoPValue(pvalDTMWins)`
- Senso NBWin `r echoPValue(pvalDTSWins)`
- Logique NBWin `r echoPValue(pvalDTLWins)`

- All NBFails `r echoPValue(pvalDTFails)`
- Motrice NBFails `r echoPValue(pvalDTMFails)`
- Senso NBFails `r echoPValue(pvalDTSFails)`
- Logique NBFails `r echoPValue(pvalDTLFails)`

# Analyses complémentaires

<p align = "justify" >&nbsp;&nbsp; On teste ici une faiblesse éventuelle du modèle. Nous considérons qu'un joueur a une perception faussée de la difficultée si la difficulté objective globale $d_{og}$ est différente de la difficulté subjective $d_{s}$. $d_{og}$ est calculée sur l'ensemble du groupe . $d_{s}$ correspond à la mise du joueur normalisée. Nous étudions le rapport entre nombre d'échecs consécutifs $n_{fail}$ ou nombre de réussites consécutifs $n_{win}$ et l'erreur d'estimation $\epsilon = d_{s} - d_{og}$. </p>

<p align = "justify" >&nbsp;&nbsp; $d_{og}$ a une faiblesse: elle est calculée sur l'ensemble du groupe et donc ne tient pas compte du niveau spécifique de chaque joueur, elle s'éloigne donc de la difficulté réelle $d_{r}$ pour les joueurs qui sortent de la moyenne du groupe, bons ou mauvais. Donc plus un joueur s'éloigne de la moyenne des joueurs, plus l'erreur d'évaluation de la difficulté va être importante: même si $d_{s}$ est parfaite, $\mid d_{s}-d_{og} \mid$ va augmenter car $d_{og}$ devient de plus en plus fausse. Autrement dit, la correlation entre $n_{win}$ et $\epsilon$ provient elle d'une erreur sur la difficulté subjective (exces de confiance) ou sur la difficulté objective. Car justement, plus un joueur est bon (ou mauvais) plus il a de chance d'avoir des suites de succès (ou d'échecs), avant que la difficulté se soit adaptée, ce qui pourrait expliquer une corrélation entre $d_{og}$ et $n_{win}$.</p>

# Idees
- enregistrer les timecodes a chaque ligne, pouir filtrer ceux qui jouent très vite ou très lentement, ou regarder les temps de réponse
- mettre difficulté totalement aléatoire (supprimer le lien entre d(n-1) et d(n))
- avoir une mise plus précise que 0/1


